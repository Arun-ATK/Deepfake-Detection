{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "DS_TEMPORAL = 'dataset_temporal/'\n",
    "\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "SEG = ['seg_1_', 'seg_2_', 'seg_3_', 'seg_4_', 'seg_5_']\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CHECKPOINT_PATH = 'models/SRM_Model/checkpoints/'\n",
    "SAVE_METRICS_PATH = 'models/SRM_Model/metrics/'\n",
    "SAVE_MODEL_PATH = 'models/SRM_Model/final_model/'\n",
    "BACKUP_MODEL_PATH = 'models/SRM_Model/backups/'\n",
    "\n",
    "TEST_SCORE_PATH = 'test_scores/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of frames that begin a new segment (except the first segment)\n",
    "def get_segment_dividers(frame_count, num_segments):\n",
    "    segments_per_frame = math.floor(frame_count / num_segments)\n",
    "\n",
    "    return [(segments_per_frame * i) for i in range(1, num_segments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices of the frames that will be randomly selected from each segment\n",
    "# Multiple snippets indices per segment can be returned by setting the num_snippets arg \n",
    "def get_snippet_indices(segment_dividers, num_snippets):\n",
    "    start_index = 0\n",
    "    num_snippets = 1 if num_snippets <= 0 else num_snippets\n",
    "\n",
    "    snippet_indices = []\n",
    "    for end_index in segment_dividers:\n",
    "\n",
    "        # Extracting multiple snippets per segment (if needed)\n",
    "        for _ in range(num_snippets):\n",
    "            snippet_indices.append(random.randint(start_index, end_index - 1))\n",
    "\n",
    "        start_index = end_index\n",
    "        \n",
    "    return snippet_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of randomly selected snippets(PIL.Image) from each segment of the input video\n",
    "def extract_snippets(fp, num_segments, num_snippets):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    snippets = []\n",
    "\n",
    "    # If number of frames in video is less than the number of frames that need to sampled\n",
    "    # then take all frames in the video\n",
    "    if frame_count < num_segments * num_snippets:\n",
    "        for frame in vid_container.decode():\n",
    "            snippets.append(frame.to_image())\n",
    "\n",
    "    else:\n",
    "        segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "        segment_dividers = segment_dividers + [frame_count]\n",
    "\n",
    "        snippet_indices = get_snippet_indices(segment_dividers, num_snippets)\n",
    "\n",
    "        frame_index = 0\n",
    "        for frame in vid_container.decode():\n",
    "            if frame_index > max(snippet_indices):\n",
    "                break\n",
    "\n",
    "            if frame_index in snippet_indices:\n",
    "                snippets.append(frame.to_image())\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb-DF v1 & v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snippets_CDF(dataset, num_segments, num_snippets):\n",
    "    if dataset != DS_CDFV1 and dataset != DS_CDFV2:\n",
    "        print(dataset)\n",
    "        return\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    src_base_path = dataset + DS_FACE\n",
    "    dst_base_path = dataset + DS_SRM_SNIPPETS\n",
    "\n",
    "    for split in SPLIT:\n",
    "        print(f'---Split started: {split}---')\n",
    "        for class_dir in CLASS:\n",
    "            print(f'Class started: {class_dir}')\n",
    "\n",
    "            for video in os.listdir(src_base_path + split + class_dir):\n",
    "                fp = src_base_path + split + class_dir + video\n",
    "                snippets = extract_snippets(fp, num_segments, num_snippets)\n",
    "\n",
    "                for i, snippet in enumerate(snippets, start=1):\n",
    "                    seg_index = math.ceil(float(i) / num_snippets)\n",
    "                    snip_index = (i - 1) % num_snippets\n",
    "              \n",
    "                    dst = f'{dst_base_path + split + class_dir + os.path.splitext(video)[0]}_s{seg_index}_f{snip_index}.jpeg'\n",
    "                    snippet.save(dst)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V1\n",
    "save_snippets_CDF(DS_CDFV1, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V2\n",
    "save_snippets_CDF(DS_CDFV2, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Dividers: [10, 20]\n",
      "Snippets[4, 9, 15, 13, 20, 26]\n"
     ]
    }
   ],
   "source": [
    "tmp_count = 30\n",
    "tmp_seg = get_segment_dividers(tmp_count, 3)\n",
    "tmp_snip = get_snippet_indices(tmp_seg + [tmp_count], 2)\n",
    "\n",
    "print(f'Segment Dividers: {tmp_seg}')\n",
    "print(f'Snippets{tmp_snip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_input = av.open(os.path.realpath(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL + test_file))\n",
    "test_input = av.open(test_file)\n",
    "\n",
    "print(test_input.streams.video[0].frames)\n",
    "\n",
    "# for frame in test_input.decode():\n",
    "#     print(frame.key_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_FACE + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_file = DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL + test_file\n",
    "tmp_snippets = extract_snippets(test_file, 5, 1)\n",
    "\n",
    "for s in tmp_snippets:\n",
    "    s.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_and_save_image(dataset, split, class_dir):\n",
    "    img_dir = dataset + DS_SRM_SNIPPETS + split + class_dir\n",
    "\n",
    "    count = 0\n",
    "    files = os.listdir(img_dir)\n",
    "    for file in files:\n",
    "        image = Image.open(img_dir + file)\n",
    "        image_flipped = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        image_flipped.save(img_dir + os.path.splitext(file)[0] + '_flip.jpeg')\n",
    "        count += 1\n",
    "\n",
    "    print(f'{len(files)} files found.')\n",
    "    print(f'{count} files flipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(dataset, split, class_dir, factor):\n",
    "    img_dir = dataset + DS_SRM_SNIPPETS + split + class_dir\n",
    "    for file in os.listdir(img_dir):\n",
    "        image = Image.open(img_dir + file)\n",
    "\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        image_enhanced = enhancer.enhance(factor)\n",
    "\n",
    "        image_enhanced.save(img_dir + os.path.splitext(file)[0] + '_enhanced.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_and_save_image(DS_CDFV2, DS_TRAIN, CLASS_REAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_brightness(DS_CDFV2, DS_TRAIN, CLASS_REAL, 1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset, split):\n",
    "    ds = keras.utils.image_dataset_from_directory(\n",
    "        directory = dataset + DS_SRM_SNIPPETS + split,\n",
    "        labels = 'inferred',\n",
    "        label_mode = 'binary',\n",
    "        batch_size = 32,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 1\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4415 files belonging to 2 classes.\n",
      "Found 500 files belonging to 2 classes.\n",
      "Found 1100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TRAIN)\n",
    "test_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TEST)\n",
    "val_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32584 files belonging to 2 classes.\n",
      "Found 2590 files belonging to 2 classes.\n",
      "Found 6005 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TRAIN)\n",
    "test_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TEST)\n",
    "val_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Convolution**\n",
    "- Input Shape:  [batch_size, height, width, channels]\n",
    "- Filter Shape: [height, width, in_channels, filter_count]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRMLayer(keras.layers.Layer):\n",
    "    def __init__(self, strides=[1,1,1,1], padding='SAME'):\n",
    "        super(SRMLayer, self).__init__()\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "        # Set of 3 fixed SRM Filters used to extract noise & semantic features\n",
    "        self.filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_med = tf.constant([[0,  0,  0,  0, 0],\n",
    "                                       [0, -1,  2, -1, 0],\n",
    "                                       [0,  2, -4,  2, 0],\n",
    "                                       [0, -1,  2, -1, 0],\n",
    "                                       [0,  0,  0,  0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_large = tf.constant([[-1,  2,  -2,  2, -1],\n",
    "                                         [ 2, -6,   8, -6,  2],\n",
    "                                         [-2,  8, -12,  8, -2],\n",
    "                                         [ 2, -6,   8, -6,  2],\n",
    "                                         [-1,  2,  -2,  2, -1]], dtype=tf.float32)\n",
    "\n",
    "        # Learnability in SRM filters introduced by 'q' values\n",
    "        # SRM filters are divided by their respective 'q' values before convolution\n",
    "        # 'q' values are updated during backpropagation using gradient descent\n",
    "        self.q_small = self.add_weight(name='q_small',\n",
    "                                       shape=(5, 5, 3, 1),\n",
    "                                       initializer=keras.initializers.Constant(value=2.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        self.q_med = self.add_weight(name='q_med',\n",
    "                                     shape=(5, 5, 3, 1),\n",
    "                                     initializer=keras.initializers.Constant(value=4.0),\n",
    "                                     trainable=True)\n",
    "        \n",
    "        self.q_large = self.add_weight(name='q_large',\n",
    "                                       shape=(5, 5, 3, 1),\n",
    "                                       initializer=keras.initializers.Constant(value=12.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        # 3rd dimension of filters => number of input channels (Three channels)\n",
    "        self.filter_small = tf.stack([self.filter_small, self.filter_small, self.filter_small], axis=2)\n",
    "        self.filter_med   = tf.stack([self.filter_med, self.filter_med, self.filter_med], axis=2)\n",
    "        self.filter_large = tf.stack([self.filter_large, self.filter_large, self.filter_large], axis=2)\n",
    "\n",
    "        # 4th dimension of filters => number of output feature maps (One feature map)\n",
    "        # Each filter gives a single output feature map\n",
    "        self.filter_small = tf.expand_dims(self.filter_small, axis=-1)\n",
    "        self.filter_med   = tf.expand_dims(self.filter_med, axis=-1)\n",
    "        self.filter_large = tf.expand_dims(self.filter_large, axis=-1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        filter_small = tf.math.divide(self.filter_small, self.q_small)\n",
    "        filter_med   = tf.math.divide(self.filter_med, self.q_med)\n",
    "        filter_large = tf.math.divide(self.filter_large, self.q_large)\n",
    "\n",
    "        output_small = tf.nn.conv2d(inputs, filter_small, strides=self.strides, padding=self.padding)\n",
    "        output_med   = tf.nn.conv2d(inputs, filter_med,   strides=self.strides, padding=self.padding)\n",
    "        output_large = tf.nn.conv2d(inputs, filter_large, strides=self.strides, padding=self.padding)\n",
    "\n",
    "        return tf.concat([output_small, output_med, output_large], axis=3)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SRMLayer, self).get_config()\n",
    "        config.update({'strides': self.strides,\n",
    "                       'padding': self.padding,\n",
    "                       'filter_small': self.filter_small,\n",
    "                       'filter_med': self.filter_med,\n",
    "                       'filter_large': self.filter_large,\n",
    "                       'q_small': self.q_small,\n",
    "                       'q_med': self.q_med,\n",
    "                       'q_large': self.q_large})\n",
    "        \n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "XceptionNetwork = keras.applications.Xception(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (256, 256, 3),\n",
    "    pooling = max,\n",
    "    classes = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCheckPoint(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        metrics_dict = {}\n",
    "        if os.path.exists(SAVE_METRICS_PATH + 'metrics.pkl'):\n",
    "            with open(SAVE_METRICS_PATH + 'metrics.pkl', 'rb') as f:\n",
    "                metrics_dict = pickle.load(f)\n",
    "\n",
    "        for key, value in logs.items():\n",
    "            if key not in metrics_dict:\n",
    "                metrics_dict[key] = []\n",
    "\n",
    "            metrics_dict[key].append(value)\n",
    "\n",
    "        with open(SAVE_METRICS_PATH + 'metrics.pkl', 'wb') as f:\n",
    "            pickle.dump(metrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = SAVE_CHECKPOINT_PATH + 'checkpoint',\n",
    "    save_weights_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    patience = 5,\n",
    "    restore_best_weights = True,\n",
    "    start_from_epoch = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restore_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir = BACKUP_MODEL_PATH + 'backup'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring all layers are trainable (fine-tuning)\n",
    "XceptionNetwork.trainable = True\n",
    "\n",
    "# TODO: Freezing all BN layers except for first one (can be done better)\n",
    "# Freeze all BN layers\n",
    "for layer in XceptionNetwork.layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Unfreeze first BN layer\n",
    "for layer in XceptionNetwork.layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_first = False\n",
    "for layer in XceptionNetwork.layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        if seen_first == False:\n",
    "            assert layer.trainable == True\n",
    "            seen_first = True\n",
    "        else:\n",
    "            assert layer.trainable == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SRM_model(xception_training):\n",
    "    inputs = keras.layers.Input(shape=(256, 256, 3))\n",
    "    SRM_noise_maps = SRMLayer()(inputs)\n",
    "    \n",
    "    feature_maps = tf.keras.applications.xception.preprocess_input(SRM_noise_maps)\n",
    "    feature_maps = XceptionNetwork(feature_maps, training=xception_training)\n",
    "\n",
    "    features = keras.layers.Flatten()(feature_maps)\n",
    "    features = keras.layers.Dropout(0.8)(features)\n",
    "    features = keras.layers.Dense(units=130, activation=keras.layers.LeakyReLU())(features)\n",
    "    outputs = keras.layers.Dense(units=1, activation='sigmoid')(features)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name='SRM_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRM_Model = create_SRM_model(xception_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SRM_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " srm_layer_1 (SRMLayer)      (None, 256, 256, 3)       225       \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLamb  (None, 256, 256, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLam  (None, 256, 256, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 130)               17039490  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 131       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,901,326\n",
      "Trainable params: 37,792,334\n",
      "Non-trainable params: 108,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(beta_1=0.9, \n",
    "                                  beta_2=0.999, \n",
    "                                  epsilon=1e-6, \n",
    "                                  learning_rate=0.00002)\n",
    "\n",
    "SRM_Model.compile(optimizer=optimizer,\n",
    "                      loss=keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=[keras.metrics.BinaryAccuracy(), \n",
    "                               keras.metrics.Precision(), \n",
    "                               keras.metrics.Recall(),\n",
    "                               keras.metrics.AUC(),\n",
    "                               keras.metrics.FalseNegatives(),\n",
    "                               keras.metrics.FalsePositives(),\n",
    "                               keras.metrics.TrueNegatives(),\n",
    "                               keras.metrics.TruePositives()])\n",
    "\n",
    "SRM_Model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SRM and Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, val_ds, max_epochs):\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs = max_epochs,\n",
    "                        validation_data = val_ds,\n",
    "                        callbacks = [model_checkpoint_callback, \n",
    "                                     early_stopping_callback,\n",
    "                                     model_restore_callback,\n",
    "                                     MetricsCheckPoint()])\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, SRM_Model = train_model(SRM_Model, train_dataset_cdfv1, val_dataset_cdfv1, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRM_Model.save_weights(SAVE_MODEL_PATH + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1a2634d98d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRM_Model.load_weights(SAVE_MODEL_PATH + 'model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.0001214], dtype=float32),\n",
       " array([3.9997723], dtype=float32),\n",
       " array([12.0004425], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRM_Model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " srm_layer_17 (SRMLayer)     (None, 256, 256, 3)       3         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 196608)            0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 196609    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,612\n",
      "Trainable params: 196,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_srm_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256, 256, 3)),\n",
    "    SRMLayer(),\n",
    "    # XceptionPreProcessor(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tmp_srm_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                      loss=keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "tmp_srm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.], dtype=float32),\n",
       " array([4.], dtype=float32),\n",
       " array([12.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_srm_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_srm_model.fit(train_dataset_cdfv1, epochs=1, validation_data=val_dataset_cdfv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.0912213], dtype=float32),\n",
       " array([4.1425376], dtype=float32),\n",
       " array([12.13928], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_srm_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00065065],\n",
       "        [-0.00062465],\n",
       "        [-0.00713642],\n",
       "        ...,\n",
       "        [-0.00407955],\n",
       "        [ 0.00504078],\n",
       "        [ 0.00208746]], dtype=float32),\n",
       " array([-0.0025801], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_srm_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_srm_model.save_weights('models/tmp_srm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " srm_layer (SRMLayer)        (None, 256, 256, 3)       3         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 196609    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,612\n",
      "Trainable params: 196,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_srm_model_2 = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256, 256, 3)),\n",
    "    SRMLayer(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tmp_srm_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                      loss=keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "tmp_srm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.0912213], dtype=float32),\n",
       " array([4.1425376], dtype=float32),\n",
       " array([12.13928], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_srm_model_2.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x20a7b2c7370>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_srm_model_2.load_weights('models/tmp_srm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([5, 5, 3, 2])\n",
      "(32, 252, 252, 2)\n"
     ]
    }
   ],
   "source": [
    "tmp_filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                [0, 0,  0, 0, 0],\n",
    "                                [0, 1, -2, 1, 0],\n",
    "                                [0, 0,  0, 0, 0],\n",
    "                                [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "\n",
    "tmp_filter_med = tf.constant([[0,  0,  0,  0, 0],\n",
    "                              [0, -1,  2, -1, 0],\n",
    "                              [0,  2, -4,  2, 0],\n",
    "                              [0, -1,  2, -1, 0],\n",
    "                              [0,  0,  0,  0, 0]], dtype=tf.float32)\n",
    "\n",
    "tmp_filter_small = tf.expand_dims(tf.expand_dims(tmp_filter_small, axis=-1), axis=-1)\n",
    "tmp_filter_med   = tf.expand_dims(tf.expand_dims(tmp_filter_med,   axis=-1), axis=-1)\n",
    "# tf.print(tmp_filter_small.shape)\n",
    "\n",
    "tmp_filter_small = tf.tile(tmp_filter_small, [1, 1, 3, 1])\n",
    "tmp_filter_med   = tf.tile(tmp_filter_med,   [1, 1, 3, 1])\n",
    "\n",
    "tmp_filters = tf.concat([tmp_filter_small, tmp_filter_med], axis=3)\n",
    "\n",
    "tf.print(tmp_filters.shape)\n",
    "\n",
    "tmp_conv = Conv2D(filters=2, \n",
    "                  kernel_size=5, \n",
    "                  kernel_initializer=tf.keras.initializers.Constant(tmp_filters))\n",
    "\n",
    "tmp_x = tf.random.normal([32, 256, 256, 3])\n",
    "tmp_y = tmp_conv(tmp_x)\n",
    "\n",
    "print(tmp_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom SRM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SSRM, self).__init__(**kwargs)\n",
    "\n",
    "        self.filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_med = tf.constant([[0,  0,  0,  0, 0],\n",
    "                                       [0, -1,  2, -1, 0],\n",
    "                                       [0,  2, -4,  2, 0],\n",
    "                                       [0, -1,  2, -1, 0],\n",
    "                                       [0,  0,  0,  0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_large = tf.constant([[-1,  2,  -2,  2, -1],\n",
    "                                         [ 2, -6,   8, -6,  2],\n",
    "                                         [-2,  8, -12,  8, -2],\n",
    "                                         [ 2, -6,   8, -6,  2],\n",
    "                                         [-1,  2,  -2,  2, -1]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_small = tf.expand_dims(tf.expand_dims(self.filter_small, axis=-1), axis=-1)\n",
    "        self.filter_med   = tf.expand_dims(tf.expand_dims(self.filter_med,   axis=-1), axis=-1)\n",
    "        self.filter_large = tf.expand_dims(tf.expand_dims(self.filter_large, axis=-1), axis=-1)\n",
    "\n",
    "        self.filter_small = tf.tile(self.filter_small, [1, 1, 3, 1])\n",
    "        self.filter_med   = tf.tile(self.filter_med,   [1, 1, 3, 1])\n",
    "        self.filter_large = tf.tile(self.filter_large, [1, 1, 3, 1])\n",
    "        \n",
    "        def call(self, inputs):\n",
    "            output_small = tf.nn.conv2d(inputs, self.filter_small, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output_med   = tf.nn.conv2d(inputs, self.filter_med,   strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output_large = tf.nn.conv2d(inputs, self.filter_large, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            return tf.concat([output_small, output_med, output_large], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSRM_Small(Layer):\n",
    "    def __init__(self):\n",
    "        super(PSRM_Small, self).__init__()\n",
    "\n",
    "        self.filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.filter_small = tf.stack([self.filter_small, self.filter_small, self.filter_small], axis=2)\n",
    "        self.filter_small = tf.expand_dims(self.filter_small, axis=-1)\n",
    "\n",
    "        self.q_small = self.add_weight(name = 'q_small',\n",
    "                                 shape = (1, ),\n",
    "                                 initializer = tf.initializers.Constant(value=2),\n",
    "                                 trainable = True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        filter_small = tf.math.divide(self.filter_small, self.q_small)\n",
    "        return tf.nn.conv2d(inputs, filter_small, strides=[1,1,1,1], padding='SAME')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " psrm__small_6 (PSRM_Small)  (None, 256, 256, 1)       1         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,538\n",
      "Trainable params: 65,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "PSRM_Model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256,256,3)),\n",
    "    PSRM_Small(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "PSRM_Model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                   loss=keras.losses.BinaryCrossentropy(),\n",
    "                   metrics=['acc'])\n",
    "\n",
    "PSRM_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 72s 483ms/step - loss: 6.8667 - acc: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1982a8b99f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSRM_Model.fit(train_dataset_cdfv1, epochs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Custom Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMPDense(keras.layers.Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(TMPDense, self).__init__()\n",
    "\n",
    "        self.w = self.add_weight(name = 'w',\n",
    "                                 shape = (input_dim, units),\n",
    "                                 initializer = tf.initializers.random_normal,\n",
    "                                 trainable = True)\n",
    "        \n",
    "        self.b = self.add_weight(name = 'b',\n",
    "                                  shape = (units, ),\n",
    "                                  initializer = tf._initializers.zeros,\n",
    "                                  trainable = True)\n",
    "        \n",
    "        self.m = self.add_weight(name = 'm',\n",
    "                                 shape = (1, ),\n",
    "                                 initializer = tf.initializers.Constant(value=2.0),\n",
    "                                 trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        div = tf.math.divide(self.w, self.m)\n",
    "        return tf.matmul(inputs, div) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ssrm_1 (SSRM)               (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 196608)            0         \n",
      "                                                                 \n",
      " tmp_dense_2 (TMPDense)      (None, 5)                 983046    \n",
      "                                                                 \n",
      " tmp_dense_3 (TMPDense)      (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 983,053\n",
      "Trainable params: 983,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dModel = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256,256,3)),\n",
    "    SSRM(),\n",
    "    Flatten(),\n",
    "    TMPDense(5, 196608),\n",
    "    TMPDense(1, 5),\n",
    "])\n",
    "\n",
    "dModel.compile(optimizer = keras.optimizers.Adam(),\n",
    "               loss = keras.losses.BinaryCrossentropy(),\n",
    "               metrics = ['accuracy']\n",
    "               )\n",
    "\n",
    "dModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00287271],\n",
       "        [-0.04635007],\n",
       "        [ 0.03803451],\n",
       "        [-0.02399216],\n",
       "        [-0.03421838]], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([2.], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dModel.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "138/138 [==============================] - 23s 131ms/step - loss: 5.1639 - accuracy: 0.6650 - val_loss: 5.1884 - val_accuracy: 0.6636\n",
      "Epoch 2/5\n",
      "138/138 [==============================] - 10s 69ms/step - loss: 5.1708 - accuracy: 0.6648 - val_loss: 5.1884 - val_accuracy: 0.6636\n",
      "Epoch 3/5\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 5.1708 - accuracy: 0.6648 - val_loss: 5.1884 - val_accuracy: 0.6636\n",
      "Epoch 4/5\n",
      "138/138 [==============================] - 12s 82ms/step - loss: 5.1708 - accuracy: 0.6648 - val_loss: 5.1884 - val_accuracy: 0.6636\n",
      "Epoch 5/5\n",
      "138/138 [==============================] - 11s 76ms/step - loss: 5.1708 - accuracy: 0.6648 - val_loss: 5.1884 - val_accuracy: 0.6636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c33ee7e920>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dModel.fit(train_dataset_cdfv1, epochs=5, validation_data=val_dataset_cdfv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.01285018],\n",
       "        [-0.05632751],\n",
       "        [ 0.04801176],\n",
       "        [-0.01401469],\n",
       "        [-0.0242409 ]], dtype=float32),\n",
       " array([-0.00997706], dtype=float32),\n",
       " array([2.0099752], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dModel.layers[3].get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Conv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMPConv(Layer):\n",
    "    def __init__(self):\n",
    "        super(TMPConv, self).__init__()\n",
    "\n",
    "        # self.kernel = self.add_weight(name = 'kernel', \n",
    "        #                               shape = (3, 3, 3, 1),\n",
    "        #                               initializer = tf.initializers.random_normal,\n",
    "        #                               trainable = True)\n",
    "\n",
    "        self.kernel = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.kernel = tf.stack([self.kernel, self.kernel, self.kernel], axis=2)\n",
    "        self.kernel = tf.expand_dims(self.kernel, axis=-1)\n",
    "        \n",
    "        self.q = self.add_weight(name = 'q',\n",
    "                                 shape = (1, ),\n",
    "                                 initializer = tf.initializers.Constant(value=2),\n",
    "                                 trainable = True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        kernel = tf.math.divide(self.kernel, self.q)\n",
    "        return tf.nn.conv2d(inputs, kernel, strides = [1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tmp_conv (TMPConv)          (None, 256, 256, 1)       1         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,538\n",
      "Trainable params: 65,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256, 256, 3)),\n",
    "    TMPConv(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "tmp_model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "tmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 28s 199ms/step - loss: 5768.4531 - acc: 0.5832 - val_loss: 5201.2295 - val_acc: 0.3682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3000a2800>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.fit(train_dataset_cdfv1, epochs=1, validation_data=val_dataset_cdfv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.0662959], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSRM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TSRM, self).__init__(**kwargs)\n",
    "\n",
    "        self.filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.q_small = self.add_weight(shape=(),\n",
    "                                       initializer='ones',\n",
    "                                       dtype=tf.float32,\n",
    "                                       trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        filter_small = self.filter_small / self.q_small\n",
    "\n",
    "        # Input shape: [batch_size, height, width, channels]\n",
    "        # Filter shape: [height, width, in_channels, out_channels]\n",
    "\n",
    "        conv_small = tf.nn.conv2d(inputs, \n",
    "                                  tf.expand_dims(tf.expand_dims(filter_small, axis=-1), axis=-1), \n",
    "                                  strides=[1, 1, 1, 1], \n",
    "                                  padding='SAME')\n",
    "        \n",
    "        # conv_meddd = tf.nn.conv2d(inputs, filter_small, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # outputs = tf.concat([conv_small, conv_meddd], axis=-1)\n",
    "        return conv_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256, 256, 3)),\n",
    "    TSRM(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tmp_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 21s 133ms/step - loss: 722.0818 - accuracy: 0.5884 - val_loss: 549.3903 - val_accuracy: 0.4255\n"
     ]
    }
   ],
   "source": [
    "tmp_history = tmp_model.fit(train_dataset_cdfv1, epochs=1, validation_data=val_dataset_cdfv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 1, -2, 1, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  2, -4,  2, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  0,  0,  0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-2,  8, -12,  8, -2],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-1,  2,  -2,  2, -1]], dtype=float)\n",
    "\n",
    "tmp_fixed_kernals = [tmp_kernel1, tmp_kernel2, tmp_kernel3]\n",
    "tmp_custom_layer = SRMLayer(filters=3, kernel_size=(5, 5), fixed_filters=tmp_fixed_kernals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Video Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoScore():\n",
    "    def __init__(self, filename, score, true_class, fake_on_lower_half = True):\n",
    "        self.filename = filename\n",
    "        self.score = score\n",
    "        self.true_class = true_class\n",
    "        self.fake_on_lower_half = fake_on_lower_half\n",
    "\n",
    "    def get_filename(self):\n",
    "        return self.filename\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_true_class(self):\n",
    "        return self.true_class\n",
    "    \n",
    "    def get_fake_on_lower_half(self):\n",
    "        return self.fake_on_lower_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_score(model, fp):\n",
    "    frames = extract_snippets(fp, num_segments=8, num_snippets=1)\n",
    "\n",
    "    tf_frames = []\n",
    "    for frame in frames:\n",
    "        tf_frames.append(tf.convert_to_tensor(frame))\n",
    "\n",
    "    tf_frames = tf.convert_to_tensor(tf_frames)\n",
    "    results = model.predict(tf_frames, verbose=0)\n",
    "\n",
    "    return np.average(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(dataset, model):\n",
    "    video_scores = []\n",
    "\n",
    "    for class_dir in CLASS:\n",
    "        print(f'Class started: {class_dir}')\n",
    "    \n",
    "        vid_dir = dataset + DS_FACE + DS_TEST + class_dir\n",
    "        for video in os.listdir(vid_dir):\n",
    "            fp = vid_dir + video\n",
    "\n",
    "            video_score = VideoScore(video, \n",
    "                                    get_video_score(model, fp),\n",
    "                                    class_dir)\n",
    "            \n",
    "            video_scores.append(video_score)\n",
    "\n",
    "    return video_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "SRM_Model_test_scores = get_test_scores(DS_CDFV2, SRM_Model)\n",
    "\n",
    "with open(TEST_SCORE_PATH + 'srm_scores', 'wb') as f:\n",
    "    pickle.dump(SRM_Model_test_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRM_Model_FT_test_scores = get_test_scores(DS_CDFV2, SRM_Model_finetuned)\n",
    "\n",
    "with open(TEST_SCORE_PATH + 'mesonet_scores', 'wb') as f:\n",
    "    pickle.dump(SRM_Model_FT_test_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
