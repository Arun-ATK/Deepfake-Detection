{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of frames that begin a new segment (except the first segment)\n",
    "def get_segment_dividers(frame_count, num_segments):\n",
    "    segments_per_frame = math.floor(frame_count / num_segments)\n",
    "\n",
    "    return [(segments_per_frame * i) for i in range(1, num_segments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices of the frames that will be randomly selected from each segment\n",
    "# Multiple snippets indices per segment can be returned by setting the num_snippets arg \n",
    "def get_snippet_indices(segment_dividers, num_snippets):\n",
    "    start_index = 0\n",
    "    num_snippets = 1 if num_snippets <= 0 else num_snippets\n",
    "\n",
    "    snippet_indices = []\n",
    "    for end_index in segment_dividers:\n",
    "\n",
    "        # Extracting multiple snippets per segment (if needed)\n",
    "        for _ in range(num_snippets):\n",
    "            snippet_indices.append(random.randint(start_index, end_index - 1))\n",
    "\n",
    "        start_index = end_index\n",
    "        \n",
    "    return snippet_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of randomly selected snippets(PIL.Image) from each segment of the input video\n",
    "def extract_snippets(fp, num_segments, num_snippets):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    snippets = []\n",
    "\n",
    "    # If number of frames in video is less than the number of frames that need to sampled\n",
    "    # then take all frames in the video\n",
    "    if frame_count < num_segments * num_snippets:\n",
    "        for frame in vid_container.decode():\n",
    "            snippets.append(frame.to_image())\n",
    "\n",
    "    else:\n",
    "        segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "        segment_dividers = segment_dividers + [frame_count]\n",
    "\n",
    "        snippet_indices = get_snippet_indices(segment_dividers, num_snippets)\n",
    "\n",
    "        frame_index = 0\n",
    "        for frame in vid_container.decode():\n",
    "            if frame_index > max(snippet_indices):\n",
    "                break\n",
    "\n",
    "            if frame_index in snippet_indices:\n",
    "                snippets.append(frame.to_image())\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Dividers: [10, 20]\n",
      "Snippets[4, 9, 15, 13, 20, 26]\n"
     ]
    }
   ],
   "source": [
    "tmp_count = 30\n",
    "tmp_seg = get_segment_dividers(tmp_count, 3)\n",
    "tmp_snip = get_snippet_indices(tmp_seg + [tmp_count], 2)\n",
    "\n",
    "print(f'Segment Dividers: {tmp_seg}')\n",
    "print(f'Snippets{tmp_snip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_input = av.open(os.path.realpath(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL + test_file))\n",
    "test_input = av.open(test_file)\n",
    "\n",
    "print(test_input.streams.video[0].frames)\n",
    "\n",
    "# for frame in test_input.decode():\n",
    "#     print(frame.key_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_FACE + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_file = DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL + test_file\n",
    "tmp_snippets = extract_snippets(test_file, 5, 1)\n",
    "\n",
    "for s in tmp_snippets:\n",
    "    s.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb-DF v1 & v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snippets_CDF(dataset, num_segments, num_snippets):\n",
    "    if dataset != DS_CDFV1 and dataset != DS_CDFV2:\n",
    "        print(dataset)\n",
    "        return\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    src_base_path = dataset + DS_FACE\n",
    "    dst_base_path = dataset + DS_SRM_SNIPPETS\n",
    "\n",
    "    for split in SPLIT:\n",
    "        print(f'---Split started: {split}---')\n",
    "        for class_dir in CLASS:\n",
    "            print(f'Class started: {class_dir}')\n",
    "\n",
    "            for video in os.listdir(src_base_path + split + class_dir):\n",
    "                fp = src_base_path + split + class_dir + video\n",
    "                snippets = extract_snippets(fp, num_segments, num_snippets)\n",
    "\n",
    "                for i, snippet in enumerate(snippets, start=1):\n",
    "                    seg_index = math.ceil(float(i) / num_snippets)\n",
    "                    snip_index = (i - 1) % num_snippets\n",
    "              \n",
    "                    dst = f'{dst_base_path + split + class_dir + os.path.splitext(video)[0]}_s{seg_index}_f{snip_index}.jpeg'\n",
    "                    snippet.save(dst)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V1\n",
    "save_snippets_CDF(DS_CDFV1, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V2\n",
    "save_snippets_CDF(DS_CDFV2, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset, split):\n",
    "    ds = keras.utils.image_dataset_from_directory(\n",
    "        directory = dataset + DS_SRM_SNIPPETS + split,\n",
    "        labels = 'inferred',\n",
    "        label_mode = 'binary',\n",
    "        batch_size = 32,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 1\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4415 files belonging to 2 classes.\n",
      "Found 500 files belonging to 2 classes.\n",
      "Found 1100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TRAIN)\n",
    "test_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TEST)\n",
    "val_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24046 files belonging to 2 classes.\n",
      "Found 2590 files belonging to 2 classes.\n",
      "Found 6005 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TRAIN)\n",
    "test_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TEST)\n",
    "val_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_srm_filters(shape, dtype=None):\n",
    "    kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 1, -2, 1, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0]], dtype=float)\n",
    "    \n",
    "    kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  2, -4,  2, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  0,  0,  0, 0]], dtype=float)\n",
    "\n",
    "    kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-2,  8, -12,  8, -2],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-1,  2,  -2,  2, -1]], dtype=float)\n",
    "    \n",
    "    \n",
    "    kernel1 /= np.ones((5, 5), dtype=float) * 2\n",
    "    kernel2 /= np.ones((5, 5), dtype=float) * 4\n",
    "    kernel3 /= np.ones((5, 5), dtype=float) * 12\n",
    "\n",
    "    k1_3D = np.dstack([kernel1, kernel1, kernel1])\n",
    "    k2_3D = np.dstack([kernel2, kernel2, kernel2])\n",
    "    k3_3D = np.dstack([kernel3, kernel3, kernel3])\n",
    "\n",
    "    final_kernel = np.stack([k1_3D, k2_3D, k3_3D], axis=-1)\n",
    "    return tf.convert_to_tensor(final_kernel, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRMLayer(Layer):\n",
    "    def __init__(self, filters, kernel_size, fixed_filters, **kwargs):\n",
    "        super(SRMLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.fixed_filters = fixed_filters\n",
    "\n",
    "        self.q_small = self.add_weight(name='q_small',\n",
    "                                       shape=(),\n",
    "                                       initializer=keras.initializers.Constant(value=2.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        self.q_med = self.add_weight(name='q_med',\n",
    "                                     shape=(),\n",
    "                                     initializer=keras.initializers.Constant(value=4.0),\n",
    "                                     trainable=True)\n",
    "        \n",
    "        self.q_large = self.add_weight(name='q_large',\n",
    "                                       shape=(),\n",
    "                                       initializer=keras.initializers.Constant(value=12.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        def build(self, input_shape):\n",
    "            super(SRMLayer, self).build(input_shape)\n",
    "            fixed_filters = tf.constant(self.fixed_filters, dtype=tf.float32)\n",
    "            print(fixed_filters)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            fixed_filters = tf.constant(self.fixed_filters, dtype=tf.float32)\n",
    "\n",
    "            # print(fixed_filters[:, :, 0:1, :])\n",
    "\n",
    "            output1 = tf.nn.conv2d(inputs, fixed_filters[:, :, 0:1, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output2 = tf.nn.conv2d(inputs, fixed_filters[:, :, 1:2, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output3 = tf.nn.conv2d(inputs, fixed_filters[:, :, 2:3, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            output1 /= self.q_small\n",
    "            output2 /= self.q_med\n",
    "            output3 /= self.q_large\n",
    "\n",
    "            output = tf.concat([output1, output2, output3], axis=3)\n",
    "            return output\n",
    "        \n",
    "        def compute_output_shape(self, input_shape):\n",
    "            batch_size = input_shape[0]\n",
    "            height = input_shape[1]\n",
    "            width = input_shape[2]\n",
    "\n",
    "        def get_config(self):\n",
    "            config = super(SRMLayer, self).get_config()\n",
    "            config.update({'filters': self.filters,\n",
    "                           'kernel_size': self.kernel_size,\n",
    "                           'fixed_filters': self.fixed_filters})\n",
    "            \n",
    "            return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 1, -2, 1, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  2, -4,  2, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  0,  0,  0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-2,  8, -12,  8, -2],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-1,  2,  -2,  2, -1]], dtype=float)\n",
    "\n",
    "tmp_fixed_kernals = [tmp_kernel1, tmp_kernel2, tmp_kernel3]\n",
    "tmp_custom_layer = SRMLayer(filters=3, kernel_size=(5, 5), fixed_filters=tmp_fixed_kernals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = keras.Sequential()\n",
    "tmp_model.add(tmp_custom_layer)\n",
    "tmp_model.add(Flatten())\n",
    "tmp_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "tmp_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 4.0, 12.0]\n"
     ]
    }
   ],
   "source": [
    "print(tmp_model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4415 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "tmp_train = keras.utils.image_dataset_from_directory(\n",
    "    directory = DS_CDFV1 + DS_SRM_SNIPPETS + DS_TRAIN,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary',\n",
    "    batch_size = 32,\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['q_small:0', 'q_med:0', 'q_large:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['q_small:0', 'q_med:0', 'q_large:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "138/138 [==============================] - 6s 36ms/step - loss: 590.7239 - binary_accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "tmp_hist = tmp_model.fit(tmp_train,\n",
    "              epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 4.0, 12.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.layers[0].get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
