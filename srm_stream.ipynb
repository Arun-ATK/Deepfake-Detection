{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of frames that begin a new segment (except the first segment)\n",
    "def get_segment_dividers(frame_count, num_segments):\n",
    "    segments_per_frame = math.floor(frame_count / num_segments)\n",
    "\n",
    "    return [(segments_per_frame * i) for i in range(1, num_segments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices of the frames that will be randomly selected from each segment\n",
    "# Multiple snippets indices per segment can be returned by setting the num_snippets arg \n",
    "def get_snippet_indices(segment_dividers, num_snippets):\n",
    "    start_index = 0\n",
    "    num_snippets = 1 if num_snippets <= 0 else num_snippets\n",
    "\n",
    "    snippet_indices = []\n",
    "    for end_index in segment_dividers:\n",
    "\n",
    "        # Extracting multiple snippets per segment (if needed)\n",
    "        for _ in range(num_snippets):\n",
    "            snippet_indices.append(random.randint(start_index, end_index - 1))\n",
    "\n",
    "        start_index = end_index\n",
    "        \n",
    "    return snippet_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of randomly selected snippets(PIL.Image) from each segment of the input video\n",
    "def extract_snippets(fp, num_segments, num_snippets):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    snippets = []\n",
    "\n",
    "    # If number of frames in video is less than the number of frames that need to sampled\n",
    "    # then take all frames in the video\n",
    "    if frame_count < num_segments * num_snippets:\n",
    "        for frame in vid_container.decode():\n",
    "            snippets.append(frame.to_image())\n",
    "\n",
    "    else:\n",
    "        segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "        segment_dividers = segment_dividers + [frame_count]\n",
    "\n",
    "        snippet_indices = get_snippet_indices(segment_dividers, num_snippets)\n",
    "\n",
    "        frame_index = 0\n",
    "        for frame in vid_container.decode():\n",
    "            if frame_index > max(snippet_indices):\n",
    "                break\n",
    "\n",
    "            if frame_index in snippet_indices:\n",
    "                snippets.append(frame.to_image())\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Dividers: [10, 20]\n",
      "Snippets[4, 9, 15, 13, 20, 26]\n"
     ]
    }
   ],
   "source": [
    "tmp_count = 30\n",
    "tmp_seg = get_segment_dividers(tmp_count, 3)\n",
    "tmp_snip = get_snippet_indices(tmp_seg + [tmp_count], 2)\n",
    "\n",
    "print(f'Segment Dividers: {tmp_seg}')\n",
    "print(f'Snippets{tmp_snip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_input = av.open(os.path.realpath(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL + test_file))\n",
    "test_input = av.open(test_file)\n",
    "\n",
    "print(test_input.streams.video[0].frames)\n",
    "\n",
    "# for frame in test_input.decode():\n",
    "#     print(frame.key_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_FACE + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_file = DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL + test_file\n",
    "tmp_snippets = extract_snippets(test_file, 5, 1)\n",
    "\n",
    "for s in tmp_snippets:\n",
    "    s.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb-DF v1 & v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snippets_CDF(dataset, num_segments, num_snippets):\n",
    "    if dataset != DS_CDFV1 and dataset != DS_CDFV2:\n",
    "        print(dataset)\n",
    "        return\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    src_base_path = dataset + DS_FACE\n",
    "    dst_base_path = dataset + DS_SRM_SNIPPETS\n",
    "\n",
    "    for split in SPLIT:\n",
    "        print(f'---Split started: {split}---')\n",
    "        for class_dir in CLASS:\n",
    "            print(f'Class started: {class_dir}')\n",
    "\n",
    "            for video in os.listdir(src_base_path + split + class_dir):\n",
    "                fp = src_base_path + split + class_dir + video\n",
    "                snippets = extract_snippets(fp, num_segments, num_snippets)\n",
    "\n",
    "                for i, snippet in enumerate(snippets, start=1):\n",
    "                    seg_index = math.ceil(float(i) / num_snippets)\n",
    "                    snip_index = (i - 1) % num_snippets\n",
    "              \n",
    "                    dst = f'{dst_base_path + split + class_dir + os.path.splitext(video)[0]}_s{seg_index}_f{snip_index}.jpeg'\n",
    "                    snippet.save(dst)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V1\n",
    "save_snippets_CDF(DS_CDFV1, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V2\n",
    "save_snippets_CDF(DS_CDFV2, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.5 -1.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_kernel = np.array([[0, 0,  0, 0, 0],\n",
    "                       [0, 0,  0, 0, 0],\n",
    "                       [0, 1, -2, 1, 0],\n",
    "                       [0, 0,  0, 0, 0],\n",
    "                       [0, 0,  0, 0, 0]])\n",
    "\n",
    "# tmp_kernel = np.array([[0, 0,  0, 0, 0],\n",
    "#                        [0, -1,  2, -1, 0],\n",
    "#                        [0, 2, -4, 2, 0],\n",
    "#                        [0, -1,  2, -1, 0],\n",
    "#                        [0, 0,  0, 0, 0]])\n",
    "\n",
    "# tmp_kernel = np.array([[0, 0,  0, 0, 0],\n",
    "#                        [0, 0,  0, 0, 0],\n",
    "#                        [0, 1, -2, 1, 0],\n",
    "#                        [0, 0,  0, 0, 0],\n",
    "#                        [0, 0,  0, 0, 0]])\n",
    "\n",
    "tmp_eq = np.ones((5,5))  * 2\n",
    "\n",
    "tmp_kernel = tmp_kernel.astype(np.float64)\n",
    "tmp_kernel /= tmp_eq\n",
    "print(tmp_kernel)\n",
    "\n",
    "tmp_input = cv2.imread(DS_CDFV1 + DS_SRM_SNIPPETS + DS_TRAIN + CLASS_REAL + '00000_s1_f0.jpeg')\n",
    "\n",
    "tmp_output = cv2.filter2D(tmp_input, -1, tmp_kernel)\n",
    "\n",
    "tmp_output = tmp_output.astype(np.float64)\n",
    "tmp_output *= 50\n",
    "tmp_output[tmp_output > 255] = 255\n",
    "\n",
    "cv2.imwrite('tmp.jpg', tmp_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 3, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 1, -2, 1, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0]])\n",
    "\n",
    "tmp_kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  2, -4,  2, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  0,  0,  0, 0]])\n",
    "\n",
    "tmp_kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-2,  8, -12,  8, -2],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-1,  2,  -2,  2, -1]])\n",
    "\n",
    "tmp_3dk1 = np.dstack([tmp_kernel1,tmp_kernel1,tmp_kernel1])\n",
    "tmp_3dk2 = np.dstack([tmp_kernel2,tmp_kernel2,tmp_kernel2])\n",
    "tmp_3dk3 = np.dstack([tmp_kernel3,tmp_kernel3,tmp_kernel3])\n",
    "\n",
    "tmp_final = np.stack([tmp_3dk1, tmp_3dk2], axis=-1)\n",
    "tmp_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_srm_filters(shape, dtype=None):\n",
    "    kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 1, -2, 1, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0]])\n",
    "\n",
    "    kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  2, -4,  2, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  0,  0,  0, 0]])\n",
    "\n",
    "    kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-2,  8, -12,  8, -2],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-1,  2,  -2,  2, -1]])\n",
    "    \n",
    "    k1_3D = np.dstack([kernel1, kernel1, kernel1])\n",
    "    k2_3D = np.dstack([kernel2, kernel2, kernel2])\n",
    "    k3_3D = np.dstack([kernel3, kernel3, kernel3])\n",
    "\n",
    "    final_kernel = np.stack([k1_3D, k2_3D, k3_3D], axis=-1)\n",
    "    return tf.convert_to_tensor(final_kernel, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 252, 252, 3)       228       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228\n",
      "Trainable params: 228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model = keras.Sequential()\n",
    "tmp_model.add(layers.Conv2D(input_shape=(256,256,3), filters=3, kernel_size=5, kernel_initializer=init_srm_filters))\n",
    "\n",
    "tmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.]],\n",
       "\n",
       "        [[  0.,   2.,   8.],\n",
       "         [  0.,   2.,   8.],\n",
       "         [  0.,   2.,   8.]],\n",
       "\n",
       "        [[  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.]],\n",
       "\n",
       "        [[  1.,   2.,   8.],\n",
       "         [  1.,   2.,   8.],\n",
       "         [  1.,   2.,   8.]],\n",
       "\n",
       "        [[ -2.,  -4., -12.],\n",
       "         [ -2.,  -4., -12.],\n",
       "         [ -2.,  -4., -12.]],\n",
       "\n",
       "        [[  1.,   2.,   8.],\n",
       "         [  1.,   2.,   8.],\n",
       "         [  1.,   2.,   8.]],\n",
       "\n",
       "        [[  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.]],\n",
       "\n",
       "        [[  0.,   2.,   8.],\n",
       "         [  0.,   2.,   8.],\n",
       "         [  0.,   2.,   8.]],\n",
       "\n",
       "        [[  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.],\n",
       "         [  0.,  -1.,  -6.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -2.]],\n",
       "\n",
       "        [[  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   2.]],\n",
       "\n",
       "        [[  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.],\n",
       "         [  0.,   0.,  -1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
