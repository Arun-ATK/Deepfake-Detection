{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of frames that begin a new segment (except the first segment)\n",
    "def get_segment_dividers(frame_count, num_segments):\n",
    "    segments_per_frame = math.floor(frame_count / num_segments)\n",
    "\n",
    "    return [(segments_per_frame * i) for i in range(1, num_segments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices of the frames that will be randomly selected from each segment\n",
    "# Multiple snippets indices per segment can be returned by setting the num_snippets arg \n",
    "def get_snippet_indices(segment_dividers, num_snippets):\n",
    "    start_index = 0\n",
    "    num_snippets = 1 if num_snippets <= 0 else num_snippets\n",
    "\n",
    "    snippet_indices = []\n",
    "    for end_index in segment_dividers:\n",
    "\n",
    "        # Extracting multiple snippets per segment (if needed)\n",
    "        for _ in range(num_snippets):\n",
    "            snippet_indices.append(random.randint(start_index, end_index - 1))\n",
    "\n",
    "        start_index = end_index\n",
    "        \n",
    "    return snippet_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of randomly selected snippets(PIL.Image) from each segment of the input video\n",
    "def extract_snippets(fp, num_segments, num_snippets):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    snippets = []\n",
    "\n",
    "    # If number of frames in video is less than the number of frames that need to sampled\n",
    "    # then take all frames in the video\n",
    "    if frame_count < num_segments * num_snippets:\n",
    "        for frame in vid_container.decode():\n",
    "            snippets.append(frame.to_image())\n",
    "\n",
    "    else:\n",
    "        segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "        segment_dividers = segment_dividers + [frame_count]\n",
    "\n",
    "        snippet_indices = get_snippet_indices(segment_dividers, num_snippets)\n",
    "\n",
    "        frame_index = 0\n",
    "        for frame in vid_container.decode():\n",
    "            if frame_index > max(snippet_indices):\n",
    "                break\n",
    "\n",
    "            if frame_index in snippet_indices:\n",
    "                snippets.append(frame.to_image())\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Dividers: [10, 20]\n",
      "Snippets[4, 9, 15, 13, 20, 26]\n"
     ]
    }
   ],
   "source": [
    "tmp_count = 30\n",
    "tmp_seg = get_segment_dividers(tmp_count, 3)\n",
    "tmp_snip = get_snippet_indices(tmp_seg + [tmp_count], 2)\n",
    "\n",
    "print(f'Segment Dividers: {tmp_seg}')\n",
    "print(f'Snippets{tmp_snip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_input = av.open(os.path.realpath(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL + test_file))\n",
    "test_input = av.open(test_file)\n",
    "\n",
    "print(test_input.streams.video[0].frames)\n",
    "\n",
    "# for frame in test_input.decode():\n",
    "#     print(frame.key_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = os.listdir(DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL)[0]\n",
    "test_file = DS_CDFV2 + DS_FACE + DS_TRAIN + CLASS_REAL + 'id27_0005.mp4'\n",
    "# test_file = DS_CDFV1 + DS_FACE + DS_TRAIN + CLASS_REAL + test_file\n",
    "tmp_snippets = extract_snippets(test_file, 5, 1)\n",
    "\n",
    "for s in tmp_snippets:\n",
    "    s.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb-DF v1 & v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snippets_CDF(dataset, num_segments, num_snippets):\n",
    "    if dataset != DS_CDFV1 and dataset != DS_CDFV2:\n",
    "        print(dataset)\n",
    "        return\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    src_base_path = dataset + DS_FACE\n",
    "    dst_base_path = dataset + DS_SRM_SNIPPETS\n",
    "\n",
    "    for split in SPLIT:\n",
    "        print(f'---Split started: {split}---')\n",
    "        for class_dir in CLASS:\n",
    "            print(f'Class started: {class_dir}')\n",
    "\n",
    "            for video in os.listdir(src_base_path + split + class_dir):\n",
    "                fp = src_base_path + split + class_dir + video\n",
    "                snippets = extract_snippets(fp, num_segments, num_snippets)\n",
    "\n",
    "                for i, snippet in enumerate(snippets, start=1):\n",
    "                    seg_index = math.ceil(float(i) / num_snippets)\n",
    "                    snip_index = (i - 1) % num_snippets\n",
    "              \n",
    "                    dst = f'{dst_base_path + split + class_dir + os.path.splitext(video)[0]}_s{seg_index}_f{snip_index}.jpeg'\n",
    "                    snippet.save(dst)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V1\n",
    "save_snippets_CDF(DS_CDFV1, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "# CELEB DF V2\n",
    "save_snippets_CDF(DS_CDFV2, num_segments=5, num_snippets=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset, split):\n",
    "    ds = keras.utils.image_dataset_from_directory(\n",
    "        directory = dataset + DS_SRM_SNIPPETS + split,\n",
    "        labels = 'inferred',\n",
    "        label_mode = 'binary',\n",
    "        batch_size = 32,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 1\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4415 files belonging to 2 classes.\n",
      "Found 500 files belonging to 2 classes.\n",
      "Found 1100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TRAIN)\n",
    "test_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TEST)\n",
    "val_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24046 files belonging to 2 classes.\n",
      "Found 2590 files belonging to 2 classes.\n",
      "Found 6005 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TRAIN)\n",
    "test_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TEST)\n",
    "val_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_srm_filters(shape, dtype=None):\n",
    "    kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 1, -2, 1, 0],\n",
    "                        [0, 0,  0, 0, 0],\n",
    "                        [0, 0,  0, 0, 0]], dtype=float)\n",
    "    \n",
    "    kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  2, -4,  2, 0],\n",
    "                        [0, -1,  2, -1, 0],\n",
    "                        [0,  0,  0,  0, 0]], dtype=float)\n",
    "\n",
    "    kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-2,  8, -12,  8, -2],\n",
    "                        [ 2, -6,   8, -6,  2],\n",
    "                        [-1,  2,  -2,  2, -1]], dtype=float)\n",
    "    \n",
    "    \n",
    "    kernel1 /= np.ones((5, 5), dtype=float) * 2\n",
    "    kernel2 /= np.ones((5, 5), dtype=float) * 4\n",
    "    kernel3 /= np.ones((5, 5), dtype=float) * 12\n",
    "\n",
    "    k1_3D = np.dstack([kernel1, kernel1, kernel1])\n",
    "    k2_3D = np.dstack([kernel2, kernel2, kernel2])\n",
    "    k3_3D = np.dstack([kernel3, kernel3, kernel3])\n",
    "\n",
    "    final_kernel = np.stack([k1_3D, k2_3D, k3_3D], axis=-1)\n",
    "    return tf.convert_to_tensor(final_kernel, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRMLayer(Layer):\n",
    "    def __init__(self, filters, kernel_size, fixed_filters, **kwargs):\n",
    "        super(SRMLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.fixed_filters = fixed_filters\n",
    "\n",
    "        self.q_small = self.add_weight(name='q_small',\n",
    "                                       shape=(),\n",
    "                                       initializer=keras.initializers.Constant(value=2.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        self.q_med = self.add_weight(name='q_med',\n",
    "                                     shape=(),\n",
    "                                     initializer=keras.initializers.Constant(value=4.0),\n",
    "                                     trainable=True)\n",
    "        \n",
    "        self.q_large = self.add_weight(name='q_large',\n",
    "                                       shape=(),\n",
    "                                       initializer=keras.initializers.Constant(value=12.0),\n",
    "                                       trainable=True)\n",
    "        \n",
    "        def build(self, input_shape):\n",
    "            super(SRMLayer, self).build(input_shape)\n",
    "            fixed_filters = tf.constant(self.fixed_filters, dtype=tf.float32)\n",
    "            print(fixed_filters)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            fixed_filters = tf.constant(self.fixed_filters, dtype=tf.float32)\n",
    "\n",
    "            # print(fixed_filters[:, :, 0:1, :])\n",
    "\n",
    "            output1 = tf.nn.conv2d(inputs, fixed_filters[:, :, 0:1, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output2 = tf.nn.conv2d(inputs, fixed_filters[:, :, 1:2, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            output3 = tf.nn.conv2d(inputs, fixed_filters[:, :, 2:3, :], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            output1 /= self.q_small\n",
    "            output2 /= self.q_med\n",
    "            output3 /= self.q_large\n",
    "\n",
    "            output = tf.concat([output1, output2, output3], axis=3)\n",
    "            return output\n",
    "        \n",
    "        def compute_output_shape(self, input_shape):\n",
    "            batch_size = input_shape[0]\n",
    "            height = input_shape[1]\n",
    "            width = input_shape[2]\n",
    "\n",
    "        def get_config(self):\n",
    "            config = super(SRMLayer, self).get_config()\n",
    "            config.update({'filters': self.filters,\n",
    "                           'kernel_size': self.kernel_size,\n",
    "                           'fixed_filters': self.fixed_filters})\n",
    "            \n",
    "            return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Convolution**\n",
    "- Input Shape:  [batch_size, height, width, channels]\n",
    "- Filter Shape: [height, width, in_channels, filter_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([5, 5, 3, 2])\n",
      "(32, 252, 252, 2)\n"
     ]
    }
   ],
   "source": [
    "tmp_filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                [0, 0,  0, 0, 0],\n",
    "                                [0, 1, -2, 1, 0],\n",
    "                                [0, 0,  0, 0, 0],\n",
    "                                [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "\n",
    "tmp_filter_med = tf.constant([[0,  0,  0,  0, 0],\n",
    "                              [0, -1,  2, -1, 0],\n",
    "                              [0,  2, -4,  2, 0],\n",
    "                              [0, -1,  2, -1, 0],\n",
    "                              [0,  0,  0,  0, 0]], dtype=tf.float32)\n",
    "\n",
    "tmp_filter_small = tf.expand_dims(tf.expand_dims(tmp_filter_small, axis=-1), axis=-1)\n",
    "tmp_filter_med   = tf.expand_dims(tf.expand_dims(tmp_filter_med,   axis=-1), axis=-1)\n",
    "# tf.print(tmp_filter_small.shape)\n",
    "\n",
    "tmp_filter_small = tf.tile(tmp_filter_small, [1, 1, 3, 1])\n",
    "tmp_filter_med   = tf.tile(tmp_filter_med,   [1, 1, 3, 1])\n",
    "\n",
    "tmp_filters = tf.concat([tmp_filter_small, tmp_filter_med], axis=3)\n",
    "\n",
    "tf.print(tmp_filters.shape)\n",
    "\n",
    "tmp_conv = Conv2D(filters=2, \n",
    "                  kernel_size=5, \n",
    "                  kernel_initializer=tf.keras.initializers.Constant(tmp_filters))\n",
    "\n",
    "tmp_x = tf.random.normal([32, 256, 256, 3])\n",
    "tmp_y = tmp_conv(tmp_x)\n",
    "\n",
    "print(tmp_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSRM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TSRM, self).__init__(**kwargs)\n",
    "\n",
    "        self.filter_small = tf.constant([[0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 1, -2, 1, 0],\n",
    "                                         [0, 0,  0, 0, 0],\n",
    "                                         [0, 0,  0, 0, 0]], dtype=tf.float32)\n",
    "        \n",
    "        self.q_small = self.add_weight(shape=(),\n",
    "                                       initializer='ones',\n",
    "                                       dtype=tf.float32,\n",
    "                                       trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        filter_small = self.filter_small / self.q_small\n",
    "\n",
    "        # Input shape: [batch_size, height, width, channels]\n",
    "        # Filter shape: [height, width, in_channels, out_channels]\n",
    "\n",
    "        conv_small = tf.nn.conv2d(inputs, \n",
    "                                  tf.expand_dims(tf.expand_dims(filter_small, axis=-1), axis=-1), \n",
    "                                  strides=[1, 1, 1, 1], \n",
    "                                  padding='SAME')\n",
    "        \n",
    "        # conv_meddd = tf.nn.conv2d(inputs, filter_small, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # outputs = tf.concat([conv_small, conv_meddd], axis=-1)\n",
    "        return conv_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tsrm_5\" (type TSRM).\n\nin user code:\n\n    File \"C:\\Users\\Arun TK\\AppData\\Local\\Temp\\ipykernel_4440\\1975148752.py\", line 22, in call  *\n        conv_small = tf.nn.conv2d(inputs,\n\n    ValueError: Depth of output (1) is not a multiple of the number of groups (3) for '{{node tsrm_5/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, tsrm_5/ExpandDims_1)' with input shapes: [?,256,256,3], [5,5,1,1].\n\n\nCall arguments received by layer \"tsrm_5\" (type TSRM):\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tmp_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mSequential([\n\u001b[0;32m      2\u001b[0m     keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mInput(shape\u001b[39m=\u001b[39;49m(\u001b[39m256\u001b[39;49m, \u001b[39m256\u001b[39;49m, \u001b[39m3\u001b[39;49m)),\n\u001b[0;32m      3\u001b[0m     TSRM(),\n\u001b[0;32m      4\u001b[0m     Flatten(),\n\u001b[0;32m      5\u001b[0m     Dense(\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m ])\n\u001b[0;32m      8\u001b[0m tmp_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mf:\\Extra_Software\\Python\\Python\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Extra_Software\\Python\\Python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\ARUNTK~1\\AppData\\Local\\Temp\\__autograph_generated_file7daloiwi.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m filter_small \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfilter_small \u001b[39m/\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mq_small\n\u001b[1;32m---> 11\u001b[0m conv_small \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mconv2d, (ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mexpand_dims, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mexpand_dims, (ag__\u001b[39m.\u001b[39;49mld(filter_small),), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), fscope),), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), fscope)), \u001b[39mdict\u001b[39;49m(strides\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m], padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSAME\u001b[39;49m\u001b[39m'\u001b[39;49m), fscope)\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tsrm_5\" (type TSRM).\n\nin user code:\n\n    File \"C:\\Users\\Arun TK\\AppData\\Local\\Temp\\ipykernel_4440\\1975148752.py\", line 22, in call  *\n        conv_small = tf.nn.conv2d(inputs,\n\n    ValueError: Depth of output (1) is not a multiple of the number of groups (3) for '{{node tsrm_5/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, tsrm_5/ExpandDims_1)' with input shapes: [?,256,256,3], [5,5,1,1].\n\n\nCall arguments received by layer \"tsrm_5\" (type TSRM):\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "tmp_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(256, 256, 3)),\n",
    "    TSRM(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tmp_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_history = tmp_model.fit(train_dataset_cdfv1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_kernel1 = np.array([[0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 1, -2, 1, 0],\n",
    "                    [0, 0,  0, 0, 0],\n",
    "                    [0, 0,  0, 0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel2 = np.array([[0,  0,  0,  0, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  2, -4,  2, 0],\n",
    "                    [0, -1,  2, -1, 0],\n",
    "                    [0,  0,  0,  0, 0]], dtype=float)\n",
    "\n",
    "tmp_kernel3 = np.array([[-1,  2,  -2,  2, -1],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-2,  8, -12,  8, -2],\n",
    "                    [ 2, -6,   8, -6,  2],\n",
    "                    [-1,  2,  -2,  2, -1]], dtype=float)\n",
    "\n",
    "tmp_fixed_kernals = [tmp_kernel1, tmp_kernel2, tmp_kernel3]\n",
    "tmp_custom_layer = SRMLayer(filters=3, kernel_size=(5, 5), fixed_filters=tmp_fixed_kernals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
