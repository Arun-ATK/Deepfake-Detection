{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASET:\n",
    "    for top_level in TOP_LEVEL_1:\n",
    "        for split in SPLIT:\n",
    "            for class_dir in CLASS:\n",
    "                dir = dataset + top_level + split + class_dir\n",
    "\n",
    "                os.makedirs(dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASET:\n",
    "    for top_level in TOP_LEVEL_2:\n",
    "        for segment in SEGMENTS:\n",
    "            for split in SPLIT:\n",
    "                for class_dir in CLASS:\n",
    "                    dir = dataset + top_level + segment + split + class_dir\n",
    "\n",
    "                    os.makedirs(dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb-DF v1 & v2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 'dataset_original' folder inside the 'celeb_df_v1' and 'celeb_df_v2' folder. Copy the three dataset folders: Celeb-real, Celeb-synthesis, and YouTube-real inside this folder, then run the below cell to create the intermediate dataset folders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Val Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(dataset_path, split_rule_file):\n",
    "    file = open(dataset_path + split_rule_file)\n",
    "\n",
    "    for line in file:\n",
    "        [vid_class, vid_path] = line.split()\n",
    "        [_, filename] = vid_path.split('/')\n",
    "\n",
    "        # Class 0 -> Fake, Class 1 -> Real\n",
    "        class_dir = CLASS_REAL if int(vid_class) == 1 else CLASS_FAKE\n",
    "\n",
    "        org_path = dataset_path + DS_ORGINAL + vid_path\n",
    "        new_path = dataset_path + DS_SPLIT + DS_TEST + class_dir + filename\n",
    "\n",
    "        shutil.move(org_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_dataset(DS_CDFV1, 'List_of_testing_videos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_dataset(DS_CDFV2, 'List_of_testing_videos.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_train(dataset, src_dir, vid_class):\n",
    "    dst_dir = dataset + DS_SPLIT + DS_TRAIN + vid_class\n",
    "    \n",
    "    files = os.listdir(dataset + src_dir)\n",
    "    for file in files:\n",
    "        shutil.move(os.path.join(dataset + src_dir, file), dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_to_train(DS_CDFV1, DS_ORGINAL + 'Celeb-real/', CLASS_REAL)\n",
    "move_to_train(DS_CDFV1, DS_ORGINAL + 'YouTube-real/', CLASS_REAL)\n",
    "move_to_train(DS_CDFV1, DS_ORGINAL + 'Celeb-synthesis/', CLASS_FAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_to_train(DS_CDFV2, DS_ORGINAL + 'Celeb-real/', CLASS_REAL)\n",
    "move_to_train(DS_CDFV2, DS_ORGINAL + 'YouTube-real/', CLASS_REAL)\n",
    "move_to_train(DS_CDFV2, DS_ORGINAL + 'Celeb-synthesis/', CLASS_FAKE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_dataset(src_dir, dst_dir):\n",
    "    random.seed(1)\n",
    "\n",
    "    filenames = os.listdir(src_dir)\n",
    "\n",
    "    k = int(len(filenames) * 0.2)\n",
    "\n",
    "    val_filenames = random.sample(filenames, k)\n",
    "    for file in val_filenames:\n",
    "        shutil.move(os.path.join(src_dir, file), dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_val_dataset(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_REAL, \n",
    "                   DS_CDFV1 + DS_SPLIT + DS_VAL + CLASS_REAL)\n",
    "\n",
    "create_val_dataset(DS_CDFV1 + DS_SPLIT + DS_TRAIN + CLASS_FAKE, \n",
    "                   DS_CDFV1 + DS_SPLIT + DS_VAL + CLASS_FAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_val_dataset(DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_REAL, \n",
    "                   DS_CDFV2 + DS_SPLIT + DS_VAL + CLASS_REAL)\n",
    "\n",
    "create_val_dataset(DS_CDFV2 + DS_SPLIT + DS_TRAIN + CLASS_FAKE, \n",
    "                   DS_CDFV2 + DS_SPLIT + DS_VAL + CLASS_FAKE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
