{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ffmpeg-python\n",
    "* av\n",
    "* cmake\n",
    "* dlib  (based on the python version)\n",
    "* face-recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import face_recognition\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_ORG = './dataset_original/'\n",
    "DS_IFRAME = './dataset_IFrames/'\n",
    "DS_FACE = './dataset_face/'\n",
    "DS_FINAL = './dataset_final/'\n",
    "DS_SEG = './dataset_segments/'\n",
    "DS_RAW = './dataset_raw/'\n",
    "\n",
    "CELEB_REAL = 'Celeb-real/'\n",
    "CELEB_FAKE = 'Celeb-synthesis/'\n",
    "YT_REAL = 'YouTube-real/'\n",
    "\n",
    "SEG = ['seg_1_', 'seg_2_', 'seg_3_']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I-Frame Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vid = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "\n",
    "for packet in test_vid.demux():\n",
    "    for frame in packet.decode():\n",
    "        print(f'{frame.pict_type} - {frame.key_frame}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "test_output = av.open('dataset_IFrames/id0_0000.mp4', 'w')\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "out_stream = test_output.add_stream(template=in_stream)\n",
    "\n",
    "for packet in test_input.demux(in_stream):\n",
    "    if packet.dts is None:\n",
    "        continue\n",
    "\n",
    "    if packet.is_keyframe:\n",
    "        packet.stream = out_stream\n",
    "        test_output.mux(packet)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    count += 1\n",
    "    if (count == 10):\n",
    "        break\n",
    "\n",
    "    input_vid = av.open(DS_ORG + CELEB_REAL + video)\n",
    "    output_vid = av.open(DS_IFRAME + CELEB_REAL + video, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "    \n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(src_dir, dest_dir, vid_class, filename):\n",
    "    input_vid = av.open(src_dir + vid_class + filename)\n",
    "    output_vid = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from real celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    extract_frames(DS_ORG, DS_IFRAME, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from real youtube videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + YT_REAL):\n",
    "    extract_frames(DS_ORG, DS_IFRAME, YT_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from deepfake celebrity videos\n",
    "# 408 vidoes chosen at random to ensure equal amount of real and fake vidoes \n",
    "# used for training. (158 real celeb videos + 250 real youtube vidoes)\n",
    "\n",
    "video_list = random.sample(os.listdir(DS_ORG + CELEB_FAKE), 408)\n",
    "for video in video_list:\n",
    "    extract_frames(DS_ORG, DS_IFRAME, CELEB_FAKE, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MesoNet works best with images having 256x256 dimension\n",
    "# If face location borders span a smaller distance, extend the borders\n",
    "# on either side equally to ensure 256x256 image\n",
    "\n",
    "def normalize_face_borders(low, high):\n",
    "    diff = high - low\n",
    "    if diff >= 256:\n",
    "        return\n",
    "\n",
    "    x = diff / 2\n",
    "    if (low >= x): \n",
    "        low -= x\n",
    "    else:\n",
    "        x = x + (x - low) + (1 if diff % 2 == 1 else 0)\n",
    "        low = 0\n",
    "\n",
    "    high += x\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New normalize function to always make the cropped face image 256x256 dimension\n",
    "# which will be fed as input to the MesoNet\n",
    "\n",
    "def modified_normalize_face_borders(low, high, boundary):\n",
    "    diff = high - low\n",
    "\n",
    "    if diff <= 256:\n",
    "        offset = 256 - diff\n",
    "        low = max(0, min(low - offset / 2 , low))\n",
    "        high = min(boundary, max(high + (offset - offset / 2), high))\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_window(face_location, height, width):\n",
    "    face_location = (face_location[0][3], height - face_location[0][0], face_location[0][1], height - face_location[0][2])\n",
    "\n",
    "    left, right = modified_normalize_face_borders(face_location[0], face_location[2], width)\n",
    "    bot, top = modified_normalize_face_borders(face_location[3], face_location[1], height)\n",
    "\n",
    "    face_location = (left, height - top, right, height - bot)\n",
    "\n",
    "    return face_location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = av.open('dataset_IFrames/Celeb-real/id0_0000.mp4')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for frame in test_input.decode():\n",
    "    nd_frame = frame.to_ndarray()\n",
    "    img_frame = frame.to_image()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)] in css terms\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    \n",
    "    img_frame = img_frame.crop(face_location)\n",
    "    img_frame.save(f'dataset_face/Celeb-real/id0_0000_{count}.jpg')\n",
    "\n",
    "    count += 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Cropped faces to a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitrate tolerance 128000 too small for bitrate 1024000, overriding\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('dataset_IFrames/Celeb-real/id10_0001.mp4')\n",
    "test_output = av.open('dataset_Face/Celeb-real/id10_0001.mp4', 'w')\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "codec_name = in_stream.codec_context.name\n",
    "\n",
    "out_stream = test_output.add_stream(codec_name, 2)\n",
    "out_stream.width = in_stream.codec_context.width\n",
    "out_stream.height = in_stream.codec_context.height\n",
    "out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "for frame in test_input.decode(in_stream):\n",
    "    img_frame = frame.to_image()\n",
    "    nd_frame = frame.to_ndarray()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    \n",
    "    if len(face_location) == 0:\n",
    "        continue\n",
    "\n",
    "    # face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "\n",
    "    # left, right = normalize_face_borders(face_location[0], face_location[2])\n",
    "    # bot, top = normalize_face_borders(face_location[3], face_location[1])\n",
    "    # face_location = (left, top, right, bot)\n",
    "\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    img_frame = img_frame.crop(face_location)\n",
    "\n",
    "    out_frame = av.VideoFrame.from_image(img_frame)\n",
    "    out_packet = out_stream.encode(out_frame)\n",
    "    test_output.mux(out_packet)\n",
    "\n",
    "out_packet = out_stream.encode(None)\n",
    "test_output.mux(out_packet)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "            \n",
    "        face_location = get_crop_window(face_location, height, width)\n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Method to save cropped faces to video\n",
    "\n",
    "The codec resizes the video according to specified dimension.\n",
    "The face_location from face_recognition api can be directly used without normalizing borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "        \n",
    "        # since the codec resizes the video depending on specified dimension\n",
    "        # no need to normalize borders\n",
    "        face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + CELEB_REAL):\n",
    "    simple_save_cropped_faces_to_video(DS_IFRAME, DS_FACE, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + CELEB_FAKE):\n",
    "    save_cropped_faces_to_video(DS_IFRAME, DS_FACE, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + YT_REAL):\n",
    "    save_cropped_faces_to_video(DS_IFRAME, DS_FACE, YT_REAL, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing videos into Segments of 3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment each video into 3 segments\n",
    "def segment_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    total_frames = in_stream.frames\n",
    "    \n",
    "    frames_per_segment = total_frames / 3\n",
    "\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    count = 1\n",
    "    seg_no = 0\n",
    "\n",
    "    # output video dimension should be 224x224\n",
    "    output = av.open(dest_dir + vid_class + SEG[seg_no] + filename, 'w')\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        if seg_no < 2 and count > frames_per_segment:\n",
    "            count = 1\n",
    "            seg_no += 1\n",
    "            out_packet = out_stream.encode(None)\n",
    "            output.mux(out_packet)\n",
    "            output.close()\n",
    "            output = av.open(dest_dir + vid_class + SEG[seg_no] + filename, 'w')\n",
    "            out_stream = output.add_stream(codec_name, 2)\n",
    "            out_stream.width = 224\n",
    "            out_stream.height = 224\n",
    "            out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_REAL, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from fake celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_FAKE, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real youtube videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, YT_REAL, video)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoViAR (Compressed Video Action Recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Residual Feature extraction before the temporality stream\n",
    "from coviar import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode Error.\n",
      "Decoding video failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg4 @ 0xa41f8c0] time_increment_bits 0 is invalid in relation to the current bitstream, this is likely caused by a missing VOL header\n",
      "[mpeg4 @ 0xa41f8c0] time_increment_bits set to 5 bits, based on bitstream analysis\n",
      "[mpeg4 @ 0xa41f8c0] time_increment_bits 4 is invalid in relation to the current bitstream, this is likely caused by a missing VOL header\n",
      "[mpeg4 @ 0xa41f8c0] time_increment_bits set to 5 bits, based on bitstream analysis\n",
      "[mpeg4 @ 0xa41f8c0] looks like this file was encoded with (divx4/(old)xvid/opendivx) -> forcing low_delay flag\n",
      "[mpeg4 @ 0xa41f8c0] [IMGUTILS @ 0x7ffffb3facd0] Picture size 0x0 is invalid\n",
      "[mpeg4 @ 0xa41f8c0] video_get_buffer: image parameters invalid\n",
      "[mpeg4 @ 0xa41f8c0] get_buffer() failed\n",
      "[mpeg4 @ 0xa41f8c0] thread_get_buffer() failed\n",
      "[mpeg4 @ 0xa41f8c0] get_buffer() failed (-22 (nil))\n"
     ]
    }
   ],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "# input: path to video (.mp4).\n",
    "# representation_type: 0, 1, or 2. 0 for I-frames, 1 for motion vectors, 2 for residuals.\n",
    "# accumulate: True or False. True returns the accumulated representation. False returns the original compressed representations. (See paper for details. )\n",
    "# The following call returns one frame (specified by frame_index=0,1,...) of one GOP ie Group Of Pictures (specified by gop_index=0,1,...).\n",
    "\n",
    "# TODO: Supports only mpeg4 raw videos, but the dataset we use are compressed videos\n",
    "load(DS_ORG + CELEB_REAL + 'id0_0000.mp4', 0, 0, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -i './dataset_segments/Celeb-real/seg_1_id0_0000.mp4' -c:v mpeg4 -f rawvideo './dataset_raw/Celeb-real/seg_1_id0_0000.mp4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './dataset_segments/Celeb-real/seg_1_id0_0000.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:18.00, start: 0.000000, bitrate: 21 kb/s\n",
      "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 224x224 [SAR 1:1 DAR 1:1], 21 kb/s, 2 fps, 2 tbr, 16384 tbn, 2 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, rawvideo, to './dataset_raw/Celeb-real/seg_1_id0_0000.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: mpeg4, yuv420p, 224x224 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 2 fps, 2 tbn, 2 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame=  156 fps=0.0 q=2.0 Lsize=     187kB time=00:01:18.00 bitrate=  19.6kbits/s speed=1.01e+03x    \n",
      "video:187kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mpeg4 raw videos can be obtained by the following command\n",
    "# ffmpeg -i input.mp4 -c:v  -c:v mpeg4 -f rawvideo output.mp4\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -i './dataset_segments/Celeb-real/seg_1_id0_0000.mp4' -c:v mpeg4 -f rawvideo './dataset_raw/Celeb-real/temp.mp4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './dataset_segments/Celeb-real/seg_1_id0_0000.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:18.00, start: 0.000000, bitrate: 21 kb/s\n",
      "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 224x224 [SAR 1:1 DAR 1:1], 21 kb/s, 2 fps, 2 tbr, 16384 tbn, 2 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, rawvideo, to './dataset_raw/Celeb-real/temp.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: mpeg4, yuv420p, 224x224 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 2 fps, 2 tbn, 2 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame=  156 fps=0.0 q=2.0 Lsize=     187kB time=00:01:18.00 bitrate=  19.6kbits/s speed=1.21e+03x    \n",
      "video:187kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -i './dataset_raw/Celeb-real/temp.mp4' -c copy './dataset_raw/Celeb-real/seg_1_id0_0000.mp4'\n",
      "rm ./dataset_raw/Celeb-real/temp.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, m4v, from './dataset_raw/Celeb-real/temp.mp4':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile), yuv420p, 224x224 [SAR 1:1 DAR 1:1], 2 fps, 2 tbr, 1200k tbn, 2 tbc\n",
      "Output #0, mp4, to './dataset_raw/Celeb-real/seg_1_id0_0000.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 224x224 [SAR 1:1 DAR 1:1], q=2-31, 2 fps, 2 tbr, 1200k tbn, 1200k tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  156 fps=0.0 q=-1.0 Lsize=     188kB time=00:01:17.50 bitrate=  19.9kbits/s speed=3.19e+04x    \n",
      "video:187kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.810988%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c copy '{}'\".format(DS_RAW + CELEB_REAL + 'temp.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "rm = \"rm {}\".format(DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(rm)\n",
    "os.system(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "load(DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4', 5, 3, 2, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a841675ff25f49a4ab9e7622d624c1b98d5764bb9b815bae537d2b3967c7573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
