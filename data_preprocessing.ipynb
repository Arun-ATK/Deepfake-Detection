{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ffmpeg-python\n",
    "* av\n",
    "* cmake\n",
    "* dlib  (based on the python version)\n",
    "* face-recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import face_recognition\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "SEG = ['seg_1_', 'seg_2_', 'seg_3_', 'seg_4_', 'seg_5_']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I-Frame Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vid = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "\n",
    "for packet in test_vid.demux():\n",
    "    for frame in packet.decode():\n",
    "        print(f'{frame.pict_type} - {frame.key_frame}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "test_output = av.open('dataset_IFrames/id0_0000.mp4', 'w')\n",
    "\n",
    "i_frame_count = 0\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "out_stream = test_output.add_stream(template=in_stream)\n",
    "\n",
    "for packet in test_input.demux(in_stream):\n",
    "    if packet.dts is None:\n",
    "        continue\n",
    "\n",
    "    if packet.is_keyframe:\n",
    "        i_frame_count += 1\n",
    "        packet.stream = out_stream\n",
    "        test_output.mux(packet)\n",
    "\n",
    "print(i_frame_count)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    count += 1\n",
    "    if (count == 10):\n",
    "        break\n",
    "\n",
    "    input_vid = av.open(DS_ORG + CELEB_REAL + video)\n",
    "    output_vid = av.open(DS_IFRAME + CELEB_REAL + video, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "    \n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(src_dir, dest_dir, vid_class, filename):\n",
    "    input_vid = av.open(src_dir + vid_class + filename)\n",
    "    output_vid = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from all videos (Celeb-DF v1)\n",
    "\n",
    "src_base_path = DS_CDFV1 + DS_SPLIT\n",
    "dst_base_path = DS_CDFV1 + DS_IFRAMES\n",
    "\n",
    "for split in SPLIT:\n",
    "    for class_dir in CLASS:\n",
    "        for video in os.listdir(src_base_path + split + class_dir):\n",
    "            extract_frames(src_base_path + split, dst_base_path + split, class_dir, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class finished: real/\n",
      "Class started: fake/\n",
      "Class finished: fake/\n",
      "---Split finished: train_dataset/---\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class finished: real/\n",
      "Class started: fake/\n",
      "Class finished: fake/\n",
      "---Split finished: test_dataset/---\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class finished: real/\n",
      "Class started: fake/\n",
      "Class finished: fake/\n",
      "---Split finished: val_dataset/---\n"
     ]
    }
   ],
   "source": [
    "# Extracting I-Frames from all videos (Celeb-DF v2)\n",
    "\n",
    "src_base_path = DS_CDFV2 + DS_SPLIT\n",
    "dst_base_path = DS_CDFV2 + DS_IFRAMES\n",
    "\n",
    "for split in SPLIT:\n",
    "    print(f'---Split started: {split}---')\n",
    "    for class_dir in CLASS:\n",
    "        print(f'Class started: {class_dir}')\n",
    "        for video in os.listdir(src_base_path + split + class_dir):\n",
    "            extract_frames(src_base_path + split, dst_base_path + split, class_dir, video)\n",
    "\n",
    "        print(f'Class finished: {class_dir}')\n",
    "\n",
    "    print(f'---Split finished: {split}---')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MesoNet works best with images having 256x256 dimension\n",
    "# If face location borders span a smaller distance, extend the borders\n",
    "# on either side equally to ensure 256x256 image\n",
    "\n",
    "def normalize_face_borders(low, high, max_val, req_dim):\n",
    "    diff = high - low\n",
    "    if diff >= 256:\n",
    "        return\n",
    "\n",
    "    offset = float((req_dim - diff)) / 2\n",
    "    low = max(0, low - offset)\n",
    "    high = min(max_val, high + offset)\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New normalize function to always make the cropped face image 256x256 dimension\n",
    "# which will be fed as input to the MesoNet\n",
    "\n",
    "def modified_normalize_face_borders(low, high, boundary):\n",
    "    diff = high - low\n",
    "\n",
    "    if diff <= 256:\n",
    "        offset = 256 - diff\n",
    "        low = max(0, min(low - offset / 2 , low))\n",
    "        high = min(boundary, max(high + (offset - offset / 2), high))\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Location: (left, top, right, bottom)\n",
    "def modify_crop_window(face_location, height, width, req_dim):\n",
    "    left, right = normalize_face_borders(face_location[0], face_location[2], width, req_dim)\n",
    "    top, bot = normalize_face_borders(face_location[1], face_location[3], height, req_dim)\n",
    "\n",
    "    face_location = (left, top, right, bot)\n",
    "\n",
    "    return face_location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(126, 643, 216, 554)]\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('celeb_df_v1/dataset_iframes/train_dataset/fake/id0_id16_0000.mp4')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for frame in test_input.decode():\n",
    "    nd_frame = frame.to_ndarray()\n",
    "    img_frame = frame.to_image()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)] in css terms\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    \n",
    "    img_frame = img_frame.crop(face_location)\n",
    "    img_frame.save(f'dataset_face/Celeb-real/id0_0000_{count}.jpg')\n",
    "\n",
    "    count += 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Cropped faces to a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitrate tolerance 128000 too small for bitrate 1024000, overriding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=948x500 at 0x7FD450981D50>\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('dataset_IFrames/Celeb-real/id10_0001.mp4')\n",
    "test_output = av.open('dataset_Face/Celeb-real/id10_0001.mp4', 'w')\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "codec_name = in_stream.codec_context.name\n",
    "\n",
    "out_stream = test_output.add_stream(codec_name, 2)\n",
    "out_stream.width = in_stream.codec_context.width\n",
    "out_stream.height = in_stream.codec_context.height\n",
    "out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "for frame in test_input.decode(in_stream):\n",
    "    img_frame = frame.to_image()\n",
    "    nd_frame = frame.to_ndarray()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    \n",
    "    if len(face_location) == 0:\n",
    "        continue\n",
    "\n",
    "    # face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "\n",
    "    # left, right = normalize_face_borders(face_location[0], face_location[2])\n",
    "    # bot, top = normalize_face_borders(face_location[3], face_location[1])\n",
    "    # face_location = (left, top, right, bot)\n",
    "\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    img_frame = img_frame.crop(face_location)\n",
    "\n",
    "    out_frame = av.VideoFrame.from_image(img_frame)\n",
    "    out_packet = out_stream.encode(out_frame)\n",
    "    test_output.mux(out_packet)\n",
    "\n",
    "out_packet = out_stream.encode(None)\n",
    "test_output.mux(out_packet)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename, req_dim):\n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, rate=2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Origin considered at top left corner of image => right margin > left margin, bottom > top\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # if can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = (face_location[0][3], face_location[0][0], \n",
    "                         face_location[0][1], face_location[0][2])\n",
    "            \n",
    "        # Modify crop window size only if positive value given.\n",
    "        if (req_dim > 0):    \n",
    "            face_location = modify_crop_window(face_location, img_frame.height, img_frame.width, req_dim)\n",
    "            \n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video_gpu(src_dir, dest_dir, vid_class, filename, req_dim):\n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, rate=2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    frame_list = []\n",
    "    image_list = []\n",
    "    for frame in input.decode(in_stream):\n",
    "        frame_list.append(frame.to_ndarray())\n",
    "        image_list.append(frame.to_image())\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "    # Origin considered at top left corner of image => right margin > left margin, bottom > top\n",
    "    # batch mode uses GPU. Default batch size = 128\n",
    "    face_locations = face_recognition.api.batch_face_locations(frame_list, number_of_times_to_upsample=0, batch_size=8)\n",
    "    for img_frame, face_location in zip(image_list, face_locations):\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = (face_location[0][3], face_location[0][0], \n",
    "                         face_location[0][1], face_location[0][2])\n",
    "\n",
    "        # Modify crop window size only if positive value given.\n",
    "        if (req_dim > 0):    \n",
    "            face_location = modify_crop_window(face_location, img_frame.height, img_frame.width, req_dim)\n",
    "        \n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Method to save cropped faces to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The codec resizes the video according to specified dimension.\n",
    "# The face_location from face_recognition api can be directly used without normalizing borders.\n",
    "def simple_save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename):\n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "        \n",
    "        # since the codec resizes the video depending on specified dimension\n",
    "        # no need to normalize borders\n",
    "        face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Faces from all videos\n",
    "\n",
    "iframe_base_path = DS_CDFV1 + DS_IFRAMES\n",
    "face_base_path = DS_CDFV1 + DS_FACE\n",
    "\n",
    "for split in SPLIT:\n",
    "    for class_dir in CLASS:\n",
    "        for video in os.listdir(iframe_base_path + split + class_dir):\n",
    "            save_cropped_faces_to_video(iframe_base_path + split, face_base_path + split, class_dir, video, req_dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Faces from all videos (Using GPU)\n",
    "\n",
    "iframe_base_path = DS_CDFV1 + DS_IFRAMES\n",
    "face_base_path = DS_CDFV1 + DS_FACE\n",
    "\n",
    "for split in SPLIT:\n",
    "    for class_dir in CLASS:\n",
    "        for video in os.listdir(iframe_base_path + split + class_dir):\n",
    "            save_cropped_faces_to_video_gpu(iframe_base_path + split, face_base_path + split, class_dir, video, req_dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Faces from all videos\n",
    "\n",
    "iframe_base_path = DS_CDFV2 + DS_IFRAMES\n",
    "face_base_path = DS_CDFV2 + DS_FACE\n",
    "\n",
    "for split in SPLIT:\n",
    "    for class_dir in CLASS:\n",
    "        for video in os.listdir(iframe_base_path + split + class_dir):\n",
    "            save_cropped_faces_to_video(iframe_base_path + split, face_base_path + split, class_dir, video, req_dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Faces from all videos (Using GPU)\n",
    "\n",
    "iframe_base_path = DS_CDFV2 + DS_IFRAMES\n",
    "face_base_path = DS_CDFV2 + DS_FACE\n",
    "\n",
    "for split in SPLIT:\n",
    "    for class_dir in CLASS:\n",
    "        for video in os.listdir(iframe_base_path + split + class_dir):\n",
    "            save_cropped_faces_to_video_gpu(iframe_base_path + split, face_base_path + split, class_dir, video, req_dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting Videos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_video(src_dir, dest_dir, filename, no_of_segments):\n",
    "    \n",
    "    input = av.open(src_dir + filename)\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    total_frames = in_stream.frames\n",
    "    \n",
    "    frames_per_segment = total_frames / no_of_segments\n",
    "\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    count = 1\n",
    "    seg_no = 0\n",
    "\n",
    "    # output video dimension should be 224x224\n",
    "    output = av.open(dest_dir + SEG[seg_no] + filename, 'w')\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        if seg_no < no_of_segments - 1 and count > frames_per_segment:\n",
    "            count = 1\n",
    "            seg_no += 1\n",
    "            out_packet = out_stream.encode(None)\n",
    "            output.mux(out_packet)\n",
    "            output.close()\n",
    "            \n",
    "            output = av.open(dest_dir + SEG[seg_no] + filename, 'w')\n",
    "            out_stream = output.add_stream(codec_name, 2)\n",
    "            out_stream.width = 224\n",
    "            out_stream.height = 224\n",
    "            out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_REAL, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from fake celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_FAKE, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real youtube videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, YT_REAL, video)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV1 + DS_SPLIT + split + class_label\n",
    "            dest_dir = DS_CDFV1 + DS_SEGMENTS + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                segment_video(src_dir, dest_dir, video, no_of_segments + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV2 + DS_SPLIT + split + class_label\n",
    "            dest_dir = DS_CDFV2 + DS_SEGMENTS + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                segment_video(src_dir, dest_dir, video, no_of_segments + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoViAR (Compressed Video Action Recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Residual Feature extraction before the temporality stream\n",
    "from coviar import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "# input: path to video (.mp4).\n",
    "# representation_type: 0, 1, or 2. 0 for I-frames, 1 for motion vectors, 2 for residuals.\n",
    "# accumulate: True or False. True returns the accumulated representation. False returns the original compressed representations. (See paper for details. )\n",
    "# The following call returns one frame (specified by frame_index=0,1,...) of one GOP ie Group Of Pictures (specified by gop_index=0,1,...).\n",
    "\n",
    "# TODO: Supports only mpeg4 raw videos, but the dataset we use are compressed videos\n",
    "load(DS_ORG + CELEB_REAL + 'id0_0000.mp4', 0, 0, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpeg4 raw videos can be obtained by the following command\n",
    "# ffmpeg -i input.mp4 -c:v  -c:v mpeg4 -f rawvideo output.mp4\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c copy '{}'\".format(DS_RAW + CELEB_REAL + 'temp.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "rm = \"rm {}\".format(DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(rm)\n",
    "os.system(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "res_features = load(DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4', 0, 3, 2, True)\n",
    "print(res_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Compressed videos to mpeg4 raw videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_mpeg(src_dir, dest_dir, filename):\n",
    "    \n",
    "    cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(src_dir + filename, dest_dir  + 'temp.mp4')\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = \"ffmpeg -i '{}' -c copy '{}'\".format(dest_dir + 'temp.mp4', dest_dir +  filename)\n",
    "    os.system(cmd)\n",
    "\n",
    "    rm = \"rm {}\".format(dest_dir + 'temp.mp4')\n",
    "    os.system(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + CELEB_REAL):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + CELEB_FAKE):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + YT_REAL):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, YT_REAL, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV1 + DS_SEGMENTS + segment + split + class_label\n",
    "            dest_dir = DS_CDFV1 + DS_RAW + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                get_raw_mpeg(src_dir, dest_dir, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV2 + DS_SEGMENTS + segment + split + class_label\n",
    "            dest_dir = DS_CDFV2 + DS_RAW + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                get_raw_mpeg(src_dir, dest_dir, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = av.open(DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "\n",
    "open = -1\n",
    "close = 0\n",
    "gop = []\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "for packet in test_input.demux(in_stream):\n",
    "    if packet.dts is None:\n",
    "        continue\n",
    "\n",
    "    if packet.is_keyframe:\n",
    "        if open == -1:\n",
    "            open = 0\n",
    "            close = 0\n",
    "        else:\n",
    "            gop.append([open, close])\n",
    "            open = 0\n",
    "            close = 0\n",
    "            \n",
    "    close += 1\n",
    "\n",
    "gop.append([open, close])\n",
    "\n",
    "print(gop)\n",
    "test_input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "\n",
    "for video in os.listdir(DS_RAW + CELEB_REAL):\n",
    "    # extract residual feature for each frame\n",
    "    res_features = load(DS_RAW + CELEB_REAL + video, 7, 1, 2, True)\n",
    "    # print(res_features)\n",
    "\n",
    "    res_features = np.where(res_features<0,0,res_features)\n",
    "    # print(res_features)\n",
    "\n",
    "    for x in res_features:\n",
    "        for y in x:\n",
    "            print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gop_frame_index(src_dir, filename):\n",
    "    \n",
    "    input = av.open(src_dir + filename)\n",
    "\n",
    "    open = -1\n",
    "    close = 0\n",
    "    gop = []\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    for packet in input.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            if open == -1:\n",
    "                open = 0\n",
    "                close = 0\n",
    "            else:\n",
    "                gop.append([open, close])\n",
    "                open = 0\n",
    "                close = 0\n",
    "                \n",
    "        close += 1\n",
    "\n",
    "    gop.append([open, close])\n",
    "    input.close()\n",
    "\n",
    "    return gop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_residual_features(src_dir, dest_dir, filename):\n",
    "    \n",
    "    gop = get_gop_frame_index(src_dir, filename)\n",
    "        \n",
    "    input = av.open(src_dir + filename)\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    output = av.open(dest_dir + filename, 'w')\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "    \n",
    "    for gop_index, interval in enumerate(gop):\n",
    "        for frame_index in range(interval[0], interval[1]):     # [interval[0] , interval[1])\n",
    "\n",
    "            # load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "            res_feature = load(src_dir + filename, gop_index, frame_index, 2, True).astype(np.uint8)\n",
    "            res_feature = np.where(res_feature < 0, 0, res_feature)\n",
    "            res_feature = PIL.Image.fromarray(res_feature)\n",
    "\n",
    "            out_frame = av.VideoFrame.from_image(res_feature)\n",
    "            out_packet = out_stream.encode(out_frame)\n",
    "            output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + CELEB_REAL):\n",
    "    extract_residual_features(DS_RAW, DS_RES, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + CELEB_FAKE):\n",
    "    extract_residual_features(DS_RAW, DS_RES, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + YT_REAL):\n",
    "    extract_residual_features(DS_RAW, DS_RES, YT_REAL, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV1 + DS_RAW + segment + split + class_label\n",
    "            dest_dir = DS_CDFV1 + DS_RESIDUALS + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                extract_residual_features(src_dir, dest_dir, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celeb DF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_of_segments, segment in enumerate(SEGMENTS):\n",
    "    for split in SPLIT:\n",
    "        for class_label in CLASS:\n",
    "            \n",
    "            src_dir = DS_CDFV2 + DS_RAW + segment + split + class_label\n",
    "            dest_dir = DS_CDFV2 + DS_RESIDUALS + segment + split + class_label\n",
    "\n",
    "            for video in os.listdir(src_dir):\n",
    "                extract_residual_features(src_dir, dest_dir, video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a841675ff25f49a4ab9e7622d624c1b98d5764bb9b815bae537d2b3967c7573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
