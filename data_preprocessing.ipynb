{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ffmpeg-python\n",
    "* av\n",
    "* cmake\n",
    "* dlib  (based on the python version)\n",
    "* face-recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import face_recognition\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_ORG = './dataset_original/'\n",
    "DS_IFRAME = './dataset_IFrames/'\n",
    "DS_FACE = './dataset_face/'\n",
    "DS_FINAL = './dataset_final/'\n",
    "DS_SEG = './dataset_segments/'\n",
    "DS_RAW = './dataset_raw/'\n",
    "DS_RES = './dataset_residuals/'\n",
    "\n",
    "CELEB_REAL = 'Celeb-real/'\n",
    "CELEB_FAKE = 'Celeb-synthesis/'\n",
    "YT_REAL = 'YouTube-real/'\n",
    "\n",
    "SEG = ['seg_1_', 'seg_2_', 'seg_3_']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I-Frame Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vid = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "\n",
    "for packet in test_vid.demux():\n",
    "    for frame in packet.decode():\n",
    "        print(f'{frame.pict_type} - {frame.key_frame}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('dataset_original/Celeb-real/id0_0000.mp4')\n",
    "test_output = av.open('dataset_IFrames/id0_0000.mp4', 'w')\n",
    "\n",
    "i_frame_count = 0\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "out_stream = test_output.add_stream(template=in_stream)\n",
    "\n",
    "for packet in test_input.demux(in_stream):\n",
    "    if packet.dts is None:\n",
    "        continue\n",
    "\n",
    "    if packet.is_keyframe:\n",
    "        i_frame_count += 1\n",
    "        packet.stream = out_stream\n",
    "        test_output.mux(packet)\n",
    "\n",
    "print(i_frame_count)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    count += 1\n",
    "    if (count == 10):\n",
    "        break\n",
    "\n",
    "    input_vid = av.open(DS_ORG + CELEB_REAL + video)\n",
    "    output_vid = av.open(DS_IFRAME + CELEB_REAL + video, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "    \n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(src_dir, dest_dir, vid_class, filename):\n",
    "    input_vid = av.open(src_dir + vid_class + filename)\n",
    "    output_vid = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from real celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    extract_frames(DS_ORG, DS_IFRAME, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from real youtube videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + YT_REAL):\n",
    "    extract_frames(DS_ORG, DS_IFRAME, YT_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting I-Frames from deepfake celebrity videos\n",
    "# 408 vidoes chosen at random to ensure equal amount of real and fake vidoes \n",
    "# used for training. (158 real celeb videos + 250 real youtube vidoes)\n",
    "\n",
    "video_list = random.sample(os.listdir(DS_ORG + CELEB_FAKE), 408)\n",
    "for video in video_list:\n",
    "    extract_frames(DS_ORG, DS_IFRAME, CELEB_FAKE, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MesoNet works best with images having 256x256 dimension\n",
    "# If face location borders span a smaller distance, extend the borders\n",
    "# on either side equally to ensure 256x256 image\n",
    "\n",
    "def normalize_face_borders(low, high):\n",
    "    diff = high - low\n",
    "    if diff >= 256:\n",
    "        return\n",
    "\n",
    "    x = diff / 2\n",
    "    if (low >= x): \n",
    "        low -= x\n",
    "    else:\n",
    "        x = x + (x - low) + (1 if diff % 2 == 1 else 0)\n",
    "        low = 0\n",
    "\n",
    "    high += x\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New normalize function to always make the cropped face image 256x256 dimension\n",
    "# which will be fed as input to the MesoNet\n",
    "\n",
    "def modified_normalize_face_borders(low, high, boundary):\n",
    "    diff = high - low\n",
    "\n",
    "    if diff <= 256:\n",
    "        offset = 256 - diff\n",
    "        low = max(0, min(low - offset / 2 , low))\n",
    "        high = min(boundary, max(high + (offset - offset / 2), high))\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_window(face_location, height, width):\n",
    "    face_location = (face_location[0][3], height - face_location[0][0], face_location[0][1], height - face_location[0][2])\n",
    "\n",
    "    left, right = modified_normalize_face_borders(face_location[0], face_location[2], width)\n",
    "    bot, top = modified_normalize_face_borders(face_location[3], face_location[1], height)\n",
    "\n",
    "    face_location = (left, height - top, right, height - bot)\n",
    "\n",
    "    return face_location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = av.open('dataset_IFrames/Celeb-real/id0_0000.mp4')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for frame in test_input.decode():\n",
    "    nd_frame = frame.to_ndarray()\n",
    "    img_frame = frame.to_image()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)] in css terms\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    \n",
    "    img_frame = img_frame.crop(face_location)\n",
    "    img_frame.save(f'dataset_face/Celeb-real/id0_0000_{count}.jpg')\n",
    "\n",
    "    count += 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Cropped faces to a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bitrate tolerance 128000 too small for bitrate 1024000, overriding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=948x500 at 0x7FD450981D50>\n"
     ]
    }
   ],
   "source": [
    "test_input = av.open('dataset_IFrames/Celeb-real/id10_0001.mp4')\n",
    "test_output = av.open('dataset_Face/Celeb-real/id10_0001.mp4', 'w')\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "codec_name = in_stream.codec_context.name\n",
    "\n",
    "out_stream = test_output.add_stream(codec_name, 2)\n",
    "out_stream.width = in_stream.codec_context.width\n",
    "out_stream.height = in_stream.codec_context.height\n",
    "out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "for frame in test_input.decode(in_stream):\n",
    "    img_frame = frame.to_image()\n",
    "    nd_frame = frame.to_ndarray()\n",
    "\n",
    "    height, width = img_frame.height, img_frame.width\n",
    "\n",
    "    # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "    # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "    face_location = face_recognition.api.face_locations(nd_frame)\n",
    "    \n",
    "    if len(face_location) == 0:\n",
    "        continue\n",
    "\n",
    "    # face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "\n",
    "    # left, right = normalize_face_borders(face_location[0], face_location[2])\n",
    "    # bot, top = normalize_face_borders(face_location[3], face_location[1])\n",
    "    # face_location = (left, top, right, bot)\n",
    "\n",
    "    face_location = get_crop_window(face_location, height, width)\n",
    "    img_frame = img_frame.crop(face_location)\n",
    "\n",
    "    out_frame = av.VideoFrame.from_image(img_frame)\n",
    "    out_packet = out_stream.encode(out_frame)\n",
    "    test_output.mux(out_packet)\n",
    "\n",
    "out_packet = out_stream.encode(None)\n",
    "test_output.mux(out_packet)\n",
    "\n",
    "test_input.close()\n",
    "test_output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "            \n",
    "        face_location = get_crop_window(face_location, height, width)\n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Method to save cropped faces to video\n",
    "\n",
    "The codec resizes the video according to specified dimension.\n",
    "The face_location from face_recognition api can be directly used without normalizing borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_save_cropped_faces_to_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "        \n",
    "        # since the codec resizes the video depending on specified dimension\n",
    "        # no need to normalize borders\n",
    "        face_location = (face_location[0][3], face_location[0][0], face_location[0][1], face_location[0][2])\n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + CELEB_REAL):\n",
    "    simple_save_cropped_faces_to_video(DS_IFRAME, DS_FACE, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + CELEB_FAKE):\n",
    "    save_cropped_faces_to_video(DS_IFRAME, DS_FACE, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_IFRAME + YT_REAL):\n",
    "    save_cropped_faces_to_video(DS_IFRAME, DS_FACE, YT_REAL, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing videos into Segments of 3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment each video into 3 segments\n",
    "def segment_video(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    total_frames = in_stream.frames\n",
    "    \n",
    "    frames_per_segment = total_frames / 3\n",
    "\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    count = 1\n",
    "    seg_no = 0\n",
    "\n",
    "    # output video dimension should be 224x224\n",
    "    output = av.open(dest_dir + vid_class + SEG[seg_no] + filename, 'w')\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        height, width = img_frame.height, img_frame.width\n",
    "\n",
    "        if seg_no < 2 and count > frames_per_segment:\n",
    "            count = 1\n",
    "            seg_no += 1\n",
    "            out_packet = out_stream.encode(None)\n",
    "            output.mux(out_packet)\n",
    "            output.close()\n",
    "            output = av.open(dest_dir + vid_class + SEG[seg_no] + filename, 'w')\n",
    "            out_stream = output.add_stream(codec_name, 2)\n",
    "            out_stream.width = 224\n",
    "            out_stream.height = 224\n",
    "            out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_REAL, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from fake celebrity videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, CELEB_FAKE, video)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3-Segments from real youtube videos\n",
    "\n",
    "for video in os.listdir(DS_ORG + CELEB_REAL):\n",
    "    segment_video(DS_ORG, DS_SEG, YT_REAL, video)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoViAR (Compressed Video Action Recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Residual Feature extraction before the temporality stream\n",
    "from coviar import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "# input: path to video (.mp4).\n",
    "# representation_type: 0, 1, or 2. 0 for I-frames, 1 for motion vectors, 2 for residuals.\n",
    "# accumulate: True or False. True returns the accumulated representation. False returns the original compressed representations. (See paper for details. )\n",
    "# The following call returns one frame (specified by frame_index=0,1,...) of one GOP ie Group Of Pictures (specified by gop_index=0,1,...).\n",
    "\n",
    "# TODO: Supports only mpeg4 raw videos, but the dataset we use are compressed videos\n",
    "load(DS_ORG + CELEB_REAL + 'id0_0000.mp4', 0, 0, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpeg4 raw videos can be obtained by the following command\n",
    "# ffmpeg -i input.mp4 -c:v  -c:v mpeg4 -f rawvideo output.mp4\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(DS_SEG + CELEB_REAL + 'seg_1_id0_0000.mp4', DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "cmd = \"ffmpeg -i '{}' -c copy '{}'\".format(DS_RAW + CELEB_REAL + 'temp.mp4', DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "rm = \"rm {}\".format(DS_RAW + CELEB_REAL + 'temp.mp4')\n",
    "print(rm)\n",
    "os.system(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "res_features = load(DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4', 0, 3, 2, True)\n",
    "print(res_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Compressed videos to mpeg4 raw videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_mpeg(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    cmd = \"ffmpeg -i '{}' -c:v mpeg4 -f rawvideo '{}'\".format(src_dir + vid_class + filename, dest_dir + vid_class + 'temp.mp4')\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = \"ffmpeg -i '{}' -c copy '{}'\".format(dest_dir + vid_class + 'temp.mp4', dest_dir + vid_class + filename)\n",
    "    os.system(cmd)\n",
    "\n",
    "    rm = \"rm {}\".format(dest_dir + vid_class + 'temp.mp4')\n",
    "    os.system(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + CELEB_REAL):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + CELEB_FAKE):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_SEG + YT_REAL):\n",
    "    get_raw_mpeg(DS_SEG, DS_RAW, YT_REAL, video)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = av.open(DS_RAW + CELEB_REAL + 'seg_1_id0_0000.mp4')\n",
    "\n",
    "open = -1\n",
    "close = 0\n",
    "gop = []\n",
    "\n",
    "in_stream = test_input.streams.video[0]\n",
    "in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "for packet in test_input.demux(in_stream):\n",
    "    if packet.dts is None:\n",
    "        continue\n",
    "\n",
    "    if packet.is_keyframe:\n",
    "        if open == -1:\n",
    "            open = 0\n",
    "            close = 0\n",
    "        else:\n",
    "            gop.append([open, close])\n",
    "            open = 0\n",
    "            close = 0\n",
    "            \n",
    "    close += 1\n",
    "\n",
    "gop.append([open, close])\n",
    "\n",
    "print(gop)\n",
    "test_input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "\n",
    "for video in os.listdir(DS_RAW + CELEB_REAL):\n",
    "    # extract residual feature for each frame\n",
    "    res_features = load(DS_RAW + CELEB_REAL + video, 7, 1, 2, True)\n",
    "    # print(res_features)\n",
    "\n",
    "    res_features = np.where(res_features<0,0,res_features)\n",
    "    # print(res_features)\n",
    "\n",
    "    for x in res_features:\n",
    "        for y in x:\n",
    "            print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gop_frame_index(src_dir, vid_class, filename):\n",
    "    \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "\n",
    "    open = -1\n",
    "    close = 0\n",
    "    gop = []\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    for packet in input.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            if open == -1:\n",
    "                open = 0\n",
    "                close = 0\n",
    "            else:\n",
    "                gop.append([open, close])\n",
    "                open = 0\n",
    "                close = 0\n",
    "                \n",
    "        close += 1\n",
    "\n",
    "    gop.append([open, close])\n",
    "    input.close()\n",
    "\n",
    "    return gop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_residual_features(src_dir, dest_dir, vid_class, filename):\n",
    "    \n",
    "    gop = get_gop_frame_index(src_dir, vid_class, filename)\n",
    "        \n",
    "    input = av.open(src_dir + vid_class + filename)\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    output = av.open(dest_dir + vid_class + filename, 'w')\n",
    "    out_stream = output.add_stream(codec_name, 2)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "    \n",
    "    for gop_index, interval in enumerate(gop):\n",
    "        for frame_index in range(interval[0], interval[1]):     # [interval[0] , interval[1])\n",
    "\n",
    "            # load([input], [gop_index], [frame_index], [representation_type], [accumulate])\n",
    "            res_feature = load(src_dir + vid_class + filename, gop_index, frame_index, 2, True).astype(np.uint8)\n",
    "            res_feature = np.where(res_feature < 0, 0, res_feature)\n",
    "            res_feature = PIL.Image.fromarray(res_feature)\n",
    "\n",
    "            out_frame = av.VideoFrame.from_image(res_feature)\n",
    "            out_packet = out_stream.encode(out_frame)\n",
    "            output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + CELEB_REAL):\n",
    "    extract_residual_features(DS_RAW, DS_RES, CELEB_REAL, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + CELEB_FAKE):\n",
    "    extract_residual_features(DS_RAW, DS_RES, CELEB_FAKE, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in os.listdir(DS_RAW + YT_REAL):\n",
    "    extract_residual_features(DS_RAW, DS_RES, YT_REAL, video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a841675ff25f49a4ab9e7622d624c1b98d5764bb9b815bae537d2b3967c7573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
