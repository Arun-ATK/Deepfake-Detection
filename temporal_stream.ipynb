{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "O6TM7wgJaBKZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import datasets, models, layers\n",
        "\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "import os\n",
        "import av\n",
        "import shutil\n",
        "import imghdr\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "63FVafT9agmz"
      },
      "outputs": [],
      "source": [
        "DS_CDFV1 = 'celeb_df_v1/'\n",
        "DS_CDFV2 = 'celeb_df_v2/'\n",
        "\n",
        "DS_ORGINAL = 'dataset_original/'\n",
        "DS_SPLIT = 'dataset_split/'\n",
        "DS_IFRAMES = 'dataset_iframes/'\n",
        "DS_FACE = 'dataset_face/'\n",
        "DS_FACE_IMG = 'dataset_face_img/'\n",
        "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
        "DS_SEGMENTS = 'dataset_segments/'\n",
        "DS_RAW = 'dataset_raw/'\n",
        "DS_RESIDUALS = 'dataset_residuals/'\n",
        "DS_TEMPORAL = 'dataset_temporal/'\n",
        "\n",
        "MODELS = 'models/'\n",
        "\n",
        "\n",
        "SEG_1 = 'seg_1/'\n",
        "SEG_2 = 'seg_2/'\n",
        "SEG_3 = 'seg_3/'\n",
        "SEG_4 = 'seg_4/'\n",
        "SEG_5 = 'seg_5/'\n",
        "\n",
        "SEG = ['seg_1_', 'seg_2_', 'seg_3_', 'seg_4_', 'seg_5_']\n",
        "\n",
        "DS_TRAIN = 'train_dataset/'\n",
        "DS_TEST = 'test_dataset/'\n",
        "DS_VAL = 'val_dataset/'\n",
        "\n",
        "CLASS_FAKE = 'fake/'\n",
        "CLASS_REAL = 'real/'\n",
        "\n",
        "\n",
        "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
        "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
        "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
        "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
        "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
        "\n",
        "DATASET = [DS_CDFV1, DS_CDFV2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Frame Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "for dataset in DATASET:\n",
        "    for split in SPLIT:\n",
        "        if split is DS_TEST:\n",
        "            for segment in SEGMENTS:\n",
        "                for label_class in CLASS:\n",
        "                    dir = dataset + DS_TEMPORAL + split + segment + label_class\n",
        "                    os.makedirs(dir, exist_ok=True) \n",
        "        else:\n",
        "            for label_class in CLASS:\n",
        "                dir = dataset + DS_TEMPORAL + split + label_class\n",
        "                os.makedirs(dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of testing videos\n",
        "for src_dir in DATASET:\n",
        "    for label, class_label in enumerate(CLASS):\n",
        "        with open(src_dir + DS_TEMPORAL + 'testing_videos.txt', 'a+') as f:\n",
        "            for file in os.listdir(src_dir + DS_SPLIT + DS_TEST + class_label):\n",
        "                f.write(f'{file} {label}\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_frames_test(ds, dest_dir, segment, split, label, file):\n",
        "    src_dir = ds + DS_RESIDUALS + segment + split + label\n",
        "\n",
        "    for index, curr_segment in enumerate(SEGMENTS):\n",
        "        if curr_segment > segment:\n",
        "            break\n",
        "\n",
        "        residual_file = src_dir + SEG[index] + file\n",
        "        os.makedirs(dest_dir + SEGMENTS[index], exist_ok=True)\n",
        "\n",
        "        vid = av.open(residual_file)\n",
        "\n",
        "        for count, frame in enumerate(vid.decode()):\n",
        "            image = frame.to_image()\n",
        "            image.save(f'{dest_dir}{SEGMENTS[index]}frame_{count}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_segment_frames(ds, segment):\n",
        "    file = open(ds + DS_TEMPORAL + 'testing_videos.txt', 'r')\n",
        "    videos = file.readlines()\n",
        "\n",
        "    for video in videos:\n",
        "        [file, label] = video.split(' ')\n",
        "        label = CLASS_REAL if int(label) == 0 else CLASS_FAKE\n",
        "        \n",
        "        dest_dir = ds + DS_TEMPORAL + DS_TEST + segment + label + '/' + file +'/'\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "        extract_frames_test(ds, dest_dir, segment, DS_TEST, label, file)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_segment_frames(DS_CDFV1, SEG_2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_frames_train_val(ds):\n",
        "    for split in SPLIT:\n",
        "        if split == DS_TEST:\n",
        "            continue\n",
        "        else:\n",
        "            for label_class in CLASS:\n",
        "                src_dir = ds + DS_RESIDUALS + SEG_1 + split + label_class\n",
        "                dest_dir = ds + DS_TEMPORAL + split + label_class\n",
        "            \n",
        "                for id, video in enumerate(os.listdir(src_dir)):\n",
        "                    vid = av.open(src_dir + video)\n",
        "\n",
        "                    for count, frame in enumerate(vid.decode()):\n",
        "                        image = frame.to_image()\n",
        "                        image.save(f'{dest_dir}frame_{count}_vid_{id}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_frames_train_val(DS_CDFV1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5ExoVSa3bT"
      },
      "source": [
        "# ResNet-18 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TaBcyV3NarBy"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(Model):\n",
        "\n",
        "    def __init__(self, channels: int, down_sample = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras)\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        \n",
        "        self.bn_1 = BatchNormalization()\n",
        "\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        \n",
        "        self.bn_2 = BatchNormalization()\n",
        "\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            \n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nkGQqOjebWfz"
      },
      "outputs": [],
      "source": [
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        \n",
        "        self.init_bn = BatchNormalization()\n",
        "\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odnGR1kkbrYs",
        "outputId": "2d323d08-757d-4883-bb70-22948881d1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"res_net18_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          multiple                  9472      \n",
            "                                                                 \n",
            " batch_normalization_60 (Bat  multiple                 256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " resnet_block_24 (ResnetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_25 (ResnetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_26 (ResnetBloc  multiple                 231296    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_27 (ResnetBloc  multiple                 296192    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_28 (ResnetBloc  multiple                 921344    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_29 (ResnetBloc  multiple                 1182208   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_30 (ResnetBloc  multiple                 3677696   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_31 (ResnetBloc  multiple                 4723712   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d_3   multiple                 0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,191,938\n",
            "Trainable params: 11,182,338\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape = (None, 224, 224, 3)\n",
        "\n",
        "model = ResNet18(2)\n",
        "model.build(input_shape)\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    0.001,\n",
        "    decay_steps = 10,\n",
        "    decay_rate = 0.1,\n",
        "    staircase = False)\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = lr_schedule), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = [keras.metrics.BinaryAccuracy(), \n",
        "                         keras.metrics.Precision(), \n",
        "                         keras.metrics.Recall(),\n",
        "                         keras.metrics.AUC()])\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_val_dataset(train_src, val_src):\n",
        "\n",
        "  train_ds = keras.utils.image_dataset_from_directory(\n",
        "        directory = train_src,\n",
        "        labels = 'inferred',\n",
        "        label_mode = 'categorical',\n",
        "        batch_size = 32,\n",
        "        image_size = (224, 224),\n",
        "        color_mode = 'rgb',\n",
        "        shuffle = True,\n",
        "        seed = 1\n",
        "    )\n",
        "\n",
        "  for data, labels in train_ds.take(1):\n",
        "    print(data.shape)\n",
        "\n",
        "  val_ds = keras.utils.image_dataset_from_directory(\n",
        "        directory = val_src,\n",
        "        labels = 'inferred',\n",
        "        label_mode = 'categorical',\n",
        "        batch_size = 32,\n",
        "        image_size = (224, 224),\n",
        "        color_mode = 'rgb',\n",
        "        shuffle = True,\n",
        "        seed = 1\n",
        "    )\n",
        "\n",
        "  for data, labels in val_ds.take(1):\n",
        "    print(data.shape)\n",
        "\n",
        "  return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_src = DS_CDFV1 + DS_TEMPORAL + DS_TRAIN\n",
        "val_src = DS_CDFV1 + DS_TEMPORAL + DS_VAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load from checkpoint (if exists)\n",
        "try:\n",
        "    saved_model = keras.models.load_model(MODELS + 'temporal_stream')\n",
        "    model = saved_model\n",
        "\n",
        "except IOError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 359405 files belonging to 2 classes.\n",
            "(32, 224, 224, 3)\n",
            "Found 89167 files belonging to 2 classes.\n",
            "(32, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds = get_train_val_dataset(train_src, val_src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds, \n\u001b[1;32m      2\u001b[0m           epochs \u001b[39m=\u001b[39;49m max_epochs, \n\u001b[1;32m      3\u001b[0m           validation_data \u001b[39m=\u001b[39;49m val_ds,\n\u001b[1;32m      4\u001b[0m           callbacks \u001b[39m=\u001b[39;49m keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(MODELS \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtemporal_stream\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m           verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
            "File \u001b[0;32m/mnt/c/Users/Kugan raju/Desktop/CODE/FINAL YEAR PROJECT/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/mnt/c/Users/Kugan raju/Desktop/CODE/FINAL YEAR PROJECT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, \n",
        "          epochs = max_epochs, \n",
        "          validation_data = val_ds,\n",
        "          callbacks = keras.callbacks.ModelCheckpoint(MODELS + 'temporal_stream'),\n",
        "          verbose = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
