{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c17fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import shutil\n",
    "import imghdr\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tempfile\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b124727",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_CDFV1 = 'celeb_df_v1/'\n",
    "DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "DS_ORGINAL = 'dataset_original/'\n",
    "DS_SPLIT = 'dataset_split/'\n",
    "DS_IFRAMES = 'dataset_iframes/'\n",
    "DS_FACE = 'dataset_face/'\n",
    "DS_FACE_IMG = 'dataset_face_img/'\n",
    "DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "DS_SEGMENTS = 'dataset_segments/'\n",
    "DS_RAW = 'dataset_raw/'\n",
    "DS_RESIDUALS = 'dataset_residuals/'\n",
    "DS_TEMPORAL = 'dataset_temporal/'\n",
    "\n",
    "\n",
    "SEG_1 = 'seg_1/'\n",
    "SEG_2 = 'seg_2/'\n",
    "SEG_3 = 'seg_3/'\n",
    "SEG_4 = 'seg_4/'\n",
    "SEG_5 = 'seg_5/'\n",
    "\n",
    "SEG = ['seg_1_', 'seg_2_', 'seg_3_', 'seg_4_', 'seg_5_']\n",
    "\n",
    "DS_TRAIN = 'train_dataset/'\n",
    "DS_TEST = 'test_dataset/'\n",
    "DS_VAL = 'val_dataset/'\n",
    "\n",
    "CLASS_FAKE = 'fake/'\n",
    "CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef257f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CHECKPOINT_PATH = 'models/Mesonet/checkpoints/'\n",
    "SAVE_METRICS_PATH = 'models/Mesonet/metrics/'\n",
    "SAVE_MODEL_PATH = 'models/Mesonet/final_model/'\n",
    "BACKUP_MODEL_PATH = 'models/Mesonet/backups/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54994d9c",
   "metadata": {},
   "source": [
    "# Frame Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8595f1c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecbd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(fp):\n",
    "    vid_container = av.open(fp)\n",
    "\n",
    "    frames = []\n",
    "    for frame in vid_container.decode():\n",
    "        frames.append(frame.to_image())\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458eaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_face_image_dataset(dataset):\n",
    "    assert dataset == DS_CDFV1 or dataset == DS_CDFV2\n",
    "\n",
    "    src_base_path = dataset + DS_FACE\n",
    "    dst_base_path = dataset + DS_FACE_IMG\n",
    "\n",
    "    for split in SPLIT:\n",
    "        print(f'---Split started: {split}---')\n",
    "\n",
    "        for class_dir in CLASS:\n",
    "            print(f'Class started: {class_dir}')\n",
    "\n",
    "            for video in os.listdir(src_base_path + split + class_dir):\n",
    "                fp = src_base_path + split + class_dir + video\n",
    "                frames = extract_frames_from_video(fp)\n",
    "\n",
    "                for i, frame in enumerate(frames, start=1):\n",
    "                    dst = f'{dst_base_path + split + class_dir + os.path.splitext(video)[0]}_f{i}.jpeg'\n",
    "                    frame.save(dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b907ee",
   "metadata": {},
   "source": [
    "## Celeb DF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81817f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "create_face_image_dataset(DS_CDFV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae2624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Split started: train_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: test_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n",
      "---Split started: val_dataset/---\n",
      "Class started: real/\n",
      "Class started: fake/\n"
     ]
    }
   ],
   "source": [
    "create_face_image_dataset(DS_CDFV2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12a42b35",
   "metadata": {},
   "source": [
    "# Tensor Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa3c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset, split):\n",
    "    ds = keras.utils.image_dataset_from_directory(\n",
    "        directory = dataset + DS_FACE_IMG + split,\n",
    "        labels = 'inferred',\n",
    "        label_mode = 'binary',\n",
    "        batch_size = 32,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 1\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9da6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30404 files belonging to 2 classes.\n",
      "Found 3299 files belonging to 2 classes.\n",
      "Found 7507 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Celeb DF v1 Dataset\n",
    "\n",
    "train_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TRAIN)\n",
    "test_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_TEST)\n",
    "val_dataset_cdfv1 = create_tensor_dataset(DS_CDFV1, DS_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab69e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153411 files belonging to 2 classes.\n",
      "Found 16670 files belonging to 2 classes.\n",
      "Found 38675 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Celeb DF v2 Dataset\n",
    "\n",
    "train_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TRAIN)\n",
    "test_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_TEST)\n",
    "val_dataset_cdfv2 = create_tensor_dataset(DS_CDFV2, DS_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62d38e48",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fa7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_size):\n",
    "    model = keras.Sequential(name='Mesonet')\n",
    "    model.add(layers.Conv2D(input_shape=input_size, filters=8, kernel_size=3, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(input_shape=(128, 128, 8), filters=8, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
    "\n",
    "  \n",
    "    model.add(layers.Conv2D(input_shape=(64, 64, 8), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
    "\n",
    "  \n",
    "    model.add(layers.Conv2D(input_shape=(16, 16, 16), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(16))\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e5cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mesonet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 8)       224       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 8)       1608      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 16)        6416      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4112      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,785\n",
      "Trainable params: 15,689\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (256, 256, 3)\n",
    "mesonet_model = create_model(input_size)\n",
    "mesonet_model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss=keras.losses.BinaryCrossentropy(), \n",
    "              metrics = [keras.metrics.BinaryAccuracy(), \n",
    "                         keras.metrics.Precision(), \n",
    "                         keras.metrics.Recall(),\n",
    "                         keras.metrics.AUC(),\n",
    "                         keras.metrics.FalseNegatives(),\n",
    "                         keras.metrics.FalsePositives(),\n",
    "                         keras.metrics.TrueNegatives(),\n",
    "                         keras.metrics.TruePositives()])\n",
    "mesonet_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a2ab7ef",
   "metadata": {},
   "source": [
    "## Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2856983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCheckPoint(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        metrics_dict = {}\n",
    "        if os.path.exists(SAVE_METRICS_PATH + 'metrics.pkl'):\n",
    "            with open(SAVE_METRICS_PATH + 'metrics.pkl', 'rb') as f:\n",
    "                metrics_dict = pickle.load(f)\n",
    "\n",
    "        for key, value in logs.items():\n",
    "            if key not in metrics_dict:\n",
    "                metrics_dict[key] = []\n",
    "\n",
    "            metrics_dict[key].append(value)\n",
    "\n",
    "        with open(SAVE_METRICS_PATH + 'metrics.pkl', 'wb') as f:\n",
    "            pickle.dump(metrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ec2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = SAVE_CHECKPOINT_PATH + 'checkpoint',\n",
    "    save_weights_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55052ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    patience = 10,\n",
    "    restore_best_weights = True,\n",
    "    start_from_epoch = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2739ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restore_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir = BACKUP_MODEL_PATH + 'backup'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88edd4d5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b9ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, val_ds, max_epochs):\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs = max_epochs,\n",
    "                        validation_data = val_ds,\n",
    "                        callbacks = [MetricsCheckPoint(), \n",
    "                                     model_checkpoint_callback,\n",
    "                                     early_stopping_callback,\n",
    "                                     model_restore_callback])\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89062968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "951/951 [==============================] - 1342s 1s/step - loss: 1.1755 - binary_accuracy: 0.5934 - precision: 0.4293 - recall: 0.4240 - auc: 0.5715 - false_negatives: 6249.0000 - false_positives: 6114.0000 - val_loss: 0.5721 - val_binary_accuracy: 0.7271 - val_precision: 0.8319 - val_recall: 0.2257 - val_auc: 0.7223 - val_false_negatives: 1935.0000 - val_false_positives: 114.0000\n",
      "Epoch 2/2\n",
      "951/951 [==============================] - 1166s 1s/step - loss: 0.7595 - binary_accuracy: 0.6710 - precision: 0.5441 - recall: 0.4816 - auc: 0.6780 - false_negatives: 5624.0000 - false_positives: 4378.0000 - val_loss: 0.5390 - val_binary_accuracy: 0.7458 - val_precision: 0.8644 - val_recall: 0.2805 - val_auc: 0.7649 - val_false_negatives: 1798.0000 - val_false_positives: 110.0000\n"
     ]
    }
   ],
   "source": [
    "history, mesonet_model = train_model(mesonet_model, train_dataset_cdfv1, val_dataset_cdfv1, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbb53eaa",
   "metadata": {},
   "source": [
    "## Saving and Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesonet_model.save_weights(SAVE_MODEL_PATH + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesonet_model.load_weights(SAVE_MODEL_PATH + 'model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d58fc2e",
   "metadata": {},
   "source": [
    "# Model Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cea8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning only dense layers\n",
    "# Helper function uses `prune_low_magnitude` to make only the \n",
    "# Dense layers train with pruning.\n",
    "def apply_pruning_to_dense(layer):\n",
    "    \n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930a538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256, 256, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 128, 128, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 8)       1608      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128, 128, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 64, 64, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64, 64, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 16)        6416      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_2  (None, 16)               8210      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 1)                35        \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,901\n",
      "Trainable params: 15,689\n",
      "Non-trainable params: 4,212\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning = keras.models.clone_model(\n",
    "    mesonet_model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "551b10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_step = np.ceil(30585/32).astype(np.int32) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff6978bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 256, 256, 8)      442       \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 256, 256, 8)      33        \n",
      " ormalization_4 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 128, 128, 8)      1         \n",
      " ling2d_4 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 128, 128, 8)      3210      \n",
      " 5 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 128, 128, 8)      33        \n",
      " ormalization_5 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 64, 64, 8)        1         \n",
      " ling2d_5 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 64, 64, 16)       6418      \n",
      " 6 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 64, 64, 16)       65        \n",
      " ormalization_6 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 16, 16, 16)       1         \n",
      " ling2d_6 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 16, 16, 16)       12818     \n",
      " 7 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 16, 16, 16)       65        \n",
      " ormalization_7 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 4, 4, 16)         1         \n",
      " ling2d_7 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 256)              1         \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 256)              1         \n",
      " _2 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_2  (None, 16)               8210      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_leaky_r  (None, 16)               1         \n",
      " e_lu_1 (PruneLowMagnitude)                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 16)               1         \n",
      " _3 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 1)                35        \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,337\n",
      "Trainable params: 15,689\n",
      "Non-trainable params: 15,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(mesonet_model, **pruning_params)\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a84faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logdir = tempfile.mkdtemp()\n",
    "\n",
    "#callbacks = [\n",
    " # tfmot.sparsity.keras.UpdatePruningStep(),\n",
    " # tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),]\n",
    "  \n",
    "#model_for_pruning.fit(train_images, train_labels,\n",
    "#                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "#                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d936617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pretrained_weights(model, train_ds, val_ds):\n",
    "    \n",
    "    model.fit(train_ds, \n",
    "             max_epochs = 20,\n",
    "             validation_data = val_ds,\n",
    "             verbose = 1)\n",
    "    _, pretrained_weights = tempfile.mkstemp('.tf')\n",
    "    model.save_weights(pretrained_weights)\n",
    "    return pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_weights = setup_pretrained_weights()\n",
    "#model.load_weights(pretrained_weights)    ---> recommended for accuracy, can only do this once model is trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
