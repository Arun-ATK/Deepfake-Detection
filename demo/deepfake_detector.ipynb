{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'input_files/'\n",
    "INTERMEDIARY_DIR = 'intermediary_files/'\n",
    "OUTPUT_DIR = 'output_files/'\n",
    "\n",
    "TOP_DIRS = [INPUT_DIR, INTERMEDIARY_DIR, OUTPUT_DIR]\n",
    "\n",
    "IFRAME_DIR = 'iframes/'\n",
    "FACECROP_DIR = 'faces/'\n",
    "RESIDUAL_DIR = 'residual/'\n",
    "\n",
    "PREPROCESS_DIRS = [IFRAME_DIR, FACECROP_DIR, RESIDUAL_DIR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in TOP_DIRS:\n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "for dir in PREPROCESS_DIRS:\n",
    "    try:\n",
    "        os.makedirs(INTERMEDIARY_DIR + dir)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS_CDFV1 = 'celeb_df_v1/'\n",
    "# DS_CDFV2 = 'celeb_df_v2/'\n",
    "\n",
    "# DS_ORGINAL = 'dataset_original/'\n",
    "# DS_SPLIT = 'dataset_split/'\n",
    "# DS_IFRAMES = 'dataset_iframes/'\n",
    "# DS_FACE = 'dataset_face/'\n",
    "# DS_FACE_IMG = 'dataset_face_img/'\n",
    "# DS_SRM_SNIPPETS = 'dataset_srm_snippets_5/'\n",
    "# DS_SEGMENTS = 'dataset_segments/'\n",
    "# DS_RAW = 'dataset_raw/'\n",
    "# DS_RESIDUALS = 'dataset_residuals/'\n",
    "# DS_TEMPORAL = 'dataset_temporal/'\n",
    "\n",
    "# DS_FRAME_DIFF = 'dataset_frame_diff/'\n",
    "# DS_FRAME_DIFF_IMG = 'dataset_frame_diff_img/'\n",
    "\n",
    "# DS_SEG_COUNT_1 = '1_segment/'\n",
    "# DS_SEG_COUNT_2 = '2_segments/'\n",
    "# DS_SEG_COUNT_3 = '3_segments/'\n",
    "# DS_SEG_COUNT_4 = '4_segments/'\n",
    "# DS_SEG_COUNT_5 = '5_segments/'\n",
    "\n",
    "# SEG_COUNT = [DS_SEG_COUNT_1, DS_SEG_COUNT_2, DS_SEG_COUNT_3, DS_SEG_COUNT_4, DS_SEG_COUNT_5]\n",
    "\n",
    "# SEG_1 = 'seg_1/'\n",
    "# SEG_2 = 'seg_2/'\n",
    "# SEG_3 = 'seg_3/'\n",
    "# SEG_4 = 'seg_4/'\n",
    "# SEG_5 = 'seg_5/'\n",
    "\n",
    "# SEG = ['seg_1_', 'seg_2_', 'seg_3_', 'seg_4_', 'seg_5_']\n",
    "\n",
    "# DS_TRAIN = 'train_dataset/'\n",
    "# DS_TEST = 'test_dataset/'\n",
    "# DS_VAL = 'val_dataset/'\n",
    "\n",
    "# CLASS_FAKE = 'fake/'\n",
    "# CLASS_REAL = 'real/'\n",
    "\n",
    "\n",
    "# TOP_LEVEL_1 = [DS_SPLIT, DS_IFRAMES, DS_FACE, DS_FACE_IMG, DS_SRM_SNIPPETS]\n",
    "# TOP_LEVEL_2 = [DS_SEGMENTS, DS_RAW, DS_RESIDUALS]\n",
    "# SEGMENTS = [SEG_1, SEG_2, SEG_3, SEG_4, SEG_5]\n",
    "# SPLIT = [DS_TRAIN, DS_TEST, DS_VAL]\n",
    "# CLASS = [CLASS_REAL, CLASS_FAKE]\n",
    "\n",
    "# DATASET = [DS_CDFV1, DS_CDFV2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow\n",
    "\n",
    "- Read all videos present in input_files folder\n",
    "- For each video in the input directory\n",
    "    - Extract I-Frames and crop faces\n",
    "    - Extract Extract residuals\n",
    "    - save face-cropped video and residuals video\n",
    "    - In Frame-level stream\n",
    "        - Extract all frames in face-cropped video\n",
    "        - Take average of prediction results as video score\n",
    "    - In SRM stream\n",
    "        - Extract snippets from face-cropped video\n",
    "        - Take average of prediction results as video score\n",
    "    - In Temporal stream\n",
    "        - Extract all residuals from residual video\n",
    "        - Take average of prediction per segment\n",
    "        - Select the most extreme value as video score (closest to 0 or 1)\n",
    "    - In score aggregation\n",
    "        - Take average of three scores\n",
    "        - Use voting to determine class (Use extreme value of major class as video score)\n",
    "        - Use trained svm model to predict class probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_iframes(fp):\n",
    "    input_vid = av.open(fp)\n",
    "    output_vid = av.open(INTERMEDIARY_DIR + IFRAME_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MesoNet works best with images having 256x256 dimension\n",
    "# If face location borders span a smaller distance, extend the borders\n",
    "# on either side equally to ensure 256x256 image\n",
    "\n",
    "def normalize_face_borders(low, high, max_val, req_dim):\n",
    "    diff = high - low\n",
    "    if diff >= 256:\n",
    "        return\n",
    "\n",
    "    offset = float((req_dim - diff)) / 2\n",
    "    low = max(0, low - offset)\n",
    "    high = min(max_val, high + offset)\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Location: (left, top, right, bottom)\n",
    "def modify_crop_window(face_location, height, width, req_dim):\n",
    "    left, right = normalize_face_borders(face_location[0], face_location[2], width, req_dim)\n",
    "    top, bot = normalize_face_borders(face_location[1], face_location[3], height, req_dim)\n",
    "\n",
    "    face_location = (left, top, right, bot)\n",
    "\n",
    "    return face_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video(fp, req_dim):\n",
    "    input = av.open(fp)\n",
    "    output = av.open(INTERMEDIARY_DIR + FACECROP_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, rate=8)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Origin considered at top left corner of image => right margin > left margin, bottom > top\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # if can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = (face_location[0][3], face_location[0][0], \n",
    "                         face_location[0][1], face_location[0][2])\n",
    "            \n",
    "        # Modify crop window size only if positive value given.\n",
    "        if (req_dim > 0):    \n",
    "            face_location = modify_crop_window(face_location, img_frame.height, img_frame.width, req_dim)\n",
    "            \n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residual(a, b):\n",
    "    return Image.fromarray(np.asarray(a) - np.asarray(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_residuals(fp):\n",
    "    input_vid = av.open(fp)\n",
    "    output_vid = av.open(INTERMEDIARY_DIR + RESIDUAL_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output_vid.add_stream(codec_name, rate=8)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    # Extract residuals\n",
    "    frame_list = [frame for frame in input_vid.decode()]\n",
    "    \n",
    "    input_vid.seek(0)\n",
    "    iframe_index = [i for i, packet in enumerate(input_vid.demux()) if packet.is_keyframe]\n",
    "\n",
    "    residuals = []\n",
    "    gop_start_index = 0\n",
    "    for index in iframe_index:\n",
    "        if index == 0:\n",
    "            continue\n",
    "\n",
    "        residual = compute_residual(frame_list[index - 1].to_image(), frame_list[gop_start_index].to_image())\n",
    "        out_frame = av.VideoFrame.from_image(residual)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output_vid.mux(out_packet)\n",
    "\n",
    "        gop_start_index = index\n",
    "\n",
    "    residual = compute_residual(frame_list[-1].to_image(), frame_list[gop_start_index].to_image())\n",
    "    out_frame = av.VideoFrame.from_image(residual)\n",
    "    out_packet = out_stream.encode(out_frame)\n",
    "    output_vid.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output_vid.mux(out_packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(fp):\n",
    "    extract_iframes(fp)\n",
    "    save_cropped_faces_to_video(INTERMEDIARY_DIR + IFRAME_DIR + os.path.split(fp)[1], -1)\n",
    "    extract_residuals(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processed: id0_0001.mp4\n",
      "Video processed: id0_id1_0001.mp4\n",
      "Video processed: id10_0001.mp4\n",
      "Video processed: id10_id11_0001.mp4\n"
     ]
    }
   ],
   "source": [
    "filename='temp.mp4'\n",
    "filename=None\n",
    "\n",
    "# If no filename was given, process all videos in input directory\n",
    "if filename == None or not os.path.exists(filename):\n",
    "    for video in os.listdir(INPUT_DIR):\n",
    "        process_video(INPUT_DIR + video)\n",
    "\n",
    "        print(f'Video processed: {video}')\n",
    "\n",
    "# If filename is a valid file in root directory, process only that file\n",
    "else:\n",
    "    process_video(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
