{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'input_files/'\n",
    "INTERMEDIARY_DIR = 'intermediary_files/'\n",
    "OUTPUT_DIR = 'output_files/'\n",
    "\n",
    "TOP_DIRS = [INPUT_DIR, INTERMEDIARY_DIR, OUTPUT_DIR]\n",
    "\n",
    "IFRAME_DIR = 'iframes/'\n",
    "FACECROP_DIR = 'faces/'\n",
    "RESIDUAL_DIR = 'residual/'\n",
    "\n",
    "PREPROCESS_DIRS = [IFRAME_DIR, FACECROP_DIR, RESIDUAL_DIR]\n",
    "\n",
    "MESONET_PATH  = 'saved_models/mesonet/'\n",
    "SRM_PATH      = 'saved_models/srm/'\n",
    "TEMPORAL_PATH = 'saved_models/temporal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in TOP_DIRS:\n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "for dir in PREPROCESS_DIRS:\n",
    "    try:\n",
    "        os.makedirs(INTERMEDIARY_DIR + dir)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow\n",
    "\n",
    "- Read all videos present in input_files folder\n",
    "- For each video in the input directory\n",
    "    - Extract I-Frames and crop faces\n",
    "    - Extract Extract residuals\n",
    "    - save face-cropped video and residuals video\n",
    "    - In Frame-level stream\n",
    "        - Extract all frames in face-cropped video\n",
    "        - Take average of prediction results as video score\n",
    "    - In SRM stream\n",
    "        - Extract snippets from face-cropped video\n",
    "        - Take average of prediction results as video score\n",
    "    - In Temporal stream\n",
    "        - Extract all residuals from residual video\n",
    "        - Take average of prediction per segment\n",
    "        - Select the most extreme value as video score (closest to 0 or 1)\n",
    "    - In score aggregation\n",
    "        - Take average of three scores\n",
    "        - Use voting to determine class (Use extreme value of major class as video score)\n",
    "        - Use trained svm model to predict class probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_iframes(fp):\n",
    "    input_vid = av.open(fp)\n",
    "    output_vid = av.open(INTERMEDIARY_DIR + IFRAME_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    in_stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    out_stream = output_vid.add_stream(template=in_stream)\n",
    "\n",
    "    for packet in input_vid.demux(in_stream):\n",
    "        if packet.dts is None:\n",
    "            continue\n",
    "\n",
    "        if packet.is_keyframe:\n",
    "            packet.stream = out_stream\n",
    "            output_vid.mux(packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MesoNet works best with images having 256x256 dimension\n",
    "# If face location borders span a smaller distance, extend the borders\n",
    "# on either side equally to ensure 256x256 image\n",
    "\n",
    "def normalize_face_borders(low, high, max_val, req_dim):\n",
    "    diff = high - low\n",
    "    if diff >= 256:\n",
    "        return\n",
    "\n",
    "    offset = float((req_dim - diff)) / 2\n",
    "    low = max(0, low - offset)\n",
    "    high = min(max_val, high + offset)\n",
    "\n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Location: (left, top, right, bottom)\n",
    "def modify_crop_window(face_location, height, width, req_dim):\n",
    "    left, right = normalize_face_borders(face_location[0], face_location[2], width, req_dim)\n",
    "    top, bot = normalize_face_borders(face_location[1], face_location[3], height, req_dim)\n",
    "\n",
    "    face_location = (left, top, right, bot)\n",
    "\n",
    "    return face_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_faces_to_video(fp, req_dim):\n",
    "    input = av.open(fp)\n",
    "    output = av.open(INTERMEDIARY_DIR + FACECROP_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output.add_stream(codec_name, rate=8)\n",
    "    out_stream.width = 256\n",
    "    out_stream.height = 256\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    for frame in input.decode(in_stream):\n",
    "        img_frame = frame.to_image()\n",
    "        nd_frame = frame.to_ndarray()\n",
    "\n",
    "        # Face location returned by face_recognition api: [(top, right, bottom, left)]\n",
    "        # Origin considered at top left corner of image => right margin > left margin, bottom > top\n",
    "        face_location = face_recognition.api.face_locations(nd_frame)\n",
    "\n",
    "        # if can't find a face, then skip that frame\n",
    "        # TODO : sync frame skipping with temporality stream\n",
    "        if len(face_location) == 0:\n",
    "            continue\n",
    "\n",
    "        # Face location required by PIL.Image: (left, top, right, bottom)\n",
    "        face_location = (face_location[0][3], face_location[0][0], \n",
    "                         face_location[0][1], face_location[0][2])\n",
    "            \n",
    "        # Modify crop window size only if positive value given.\n",
    "        if (req_dim > 0):    \n",
    "            face_location = modify_crop_window(face_location, img_frame.height, img_frame.width, req_dim)\n",
    "            \n",
    "        img_frame = img_frame.crop(face_location)\n",
    "        \n",
    "        out_frame = av.VideoFrame.from_image(img_frame)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output.mux(out_packet)\n",
    "\n",
    "    input.close()\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residual(a, b):\n",
    "    return Image.fromarray(np.asarray(a) - np.asarray(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_residuals(fp):\n",
    "    input_vid = av.open(fp)\n",
    "    output_vid = av.open(INTERMEDIARY_DIR + RESIDUAL_DIR + os.path.split(fp)[1], 'w')\n",
    "\n",
    "    in_stream = input_vid.streams.video[0]\n",
    "    codec_name = in_stream.codec_context.name\n",
    "\n",
    "    # output video dimension should be 256x256\n",
    "    out_stream = output_vid.add_stream(codec_name, rate=8)\n",
    "    out_stream.width = 224\n",
    "    out_stream.height = 224\n",
    "    out_stream.pix_fmt = in_stream.codec_context.pix_fmt\n",
    "\n",
    "    # Extract residuals\n",
    "    frame_list = [frame for frame in input_vid.decode()]\n",
    "    \n",
    "    input_vid.seek(0)\n",
    "    iframe_index = [i for i, packet in enumerate(input_vid.demux()) if packet.is_keyframe]\n",
    "\n",
    "    residuals = []\n",
    "    gop_start_index = 0\n",
    "    for index in iframe_index:\n",
    "        if index == 0:\n",
    "            continue\n",
    "\n",
    "        residual = compute_residual(frame_list[index - 1].to_image(), frame_list[gop_start_index].to_image())\n",
    "        out_frame = av.VideoFrame.from_image(residual)\n",
    "        out_packet = out_stream.encode(out_frame)\n",
    "        output_vid.mux(out_packet)\n",
    "\n",
    "        gop_start_index = index\n",
    "\n",
    "    residual = compute_residual(frame_list[-1].to_image(), frame_list[gop_start_index].to_image())\n",
    "    out_frame = av.VideoFrame.from_image(residual)\n",
    "    out_packet = out_stream.encode(out_frame)\n",
    "    output_vid.mux(out_packet)\n",
    "\n",
    "    out_packet = out_stream.encode(None)\n",
    "    output_vid.mux(out_packet)\n",
    "\n",
    "    input_vid.close()\n",
    "    output_vid.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoScore():\n",
    "    def __init__(self, filename, score, fake_on_lower_half = True):\n",
    "        self.filename = filename\n",
    "        self.score = score\n",
    "        self.fake_on_lower_half = fake_on_lower_half\n",
    "\n",
    "    def get_filename(self):\n",
    "        return self.filename\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_fake_on_lower_half(self):\n",
    "        return self.fake_on_lower_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of frames that begin a new segment (except the first segment)\n",
    "def get_segment_dividers(frame_count, num_segments):\n",
    "    segments_per_frame = math.floor(frame_count / num_segments)\n",
    "\n",
    "    return [(segments_per_frame * i) for i in range(1, num_segments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices of the frames that will be randomly selected from each segment\n",
    "# Multiple snippets indices per segment can be returned by setting the num_snippets arg \n",
    "def get_snippet_indices(segment_dividers, num_snippets):\n",
    "    start_index = 0\n",
    "    num_snippets = 1 if num_snippets <= 0 else num_snippets\n",
    "\n",
    "    snippet_indices = []\n",
    "    for end_index in segment_dividers:\n",
    "\n",
    "        # Extracting multiple snippets per segment (if needed)\n",
    "        for _ in range(num_snippets):\n",
    "            snippet_indices.append(random.randint(start_index, end_index - 1))\n",
    "\n",
    "        start_index = end_index\n",
    "        \n",
    "    return snippet_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of randomly selected snippets(PIL.Image) from each segment of the input video\n",
    "def extract_snippets(fp, num_segments, num_snippets):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    snippets = []\n",
    "\n",
    "    # If number of frames in video is less than the number of frames that need to sampled\n",
    "    # then take all frames in the video\n",
    "    if frame_count < num_segments * num_snippets:\n",
    "        for frame in vid_container.decode():\n",
    "            snippets.append(frame.to_image())\n",
    "\n",
    "    else:\n",
    "        segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "        segment_dividers = segment_dividers + [frame_count]\n",
    "\n",
    "        snippet_indices = get_snippet_indices(segment_dividers, num_snippets)\n",
    "\n",
    "        frame_index = 0\n",
    "        for frame in vid_container.decode():\n",
    "            if frame_index > max(snippet_indices):\n",
    "                break\n",
    "\n",
    "            if frame_index in snippet_indices:\n",
    "                snippets.append(frame.to_image())\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesonet Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_size):\n",
    "    model = keras.Sequential(name='Mesonet')\n",
    "    model.add(layers.Conv2D(input_shape=input_size, filters=8, kernel_size=3, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(input_shape=(128, 128, 8), filters=8, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
    "\n",
    "  \n",
    "    model.add(layers.Conv2D(input_shape=(64, 64, 8), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
    "\n",
    "  \n",
    "    model.add(layers.Conv2D(input_shape=(16, 16, 16), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(16))\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mesonet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 8)       224       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 8)       1608      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 16)        6416      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4112      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,785\n",
      "Trainable params: 15,689\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (256, 256, 3)\n",
    "mesonet_model = create_model(input_size)\n",
    "mesonet_model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss=keras.losses.BinaryCrossentropy(), \n",
    "              metrics = [keras.metrics.BinaryAccuracy(), \n",
    "                         keras.metrics.Precision(), \n",
    "                         keras.metrics.Recall(),\n",
    "                         keras.metrics.AUC(),\n",
    "                         keras.metrics.FalseNegatives(),\n",
    "                         keras.metrics.FalsePositives(),\n",
    "                         keras.metrics.TrueNegatives(),\n",
    "                         keras.metrics.TruePositives()])\n",
    "mesonet_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRM Stream"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50v2 = tf.keras.applications.ResNet50V2(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50v2.trainable = True\n",
    "\n",
    "# TODO: Freezing all BN layers except for first one (can be done better)\n",
    "# Freeze all BN layers\n",
    "for layer in resnet50v2.layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Unfreeze first BN layer\n",
    "for layer in resnet50v2.layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input((224, 224, 3))\n",
    "x = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "x = resnet50v2(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(100, activation=LeakyReLU())(x)\n",
    "x = Dropout(0.8)(x)\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "temporal_model = keras.Model(inputs, out, name=\"temporal_stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_model.compile(optimizer = Adam(learning_rate = 0.00001), \n",
    "              loss = keras.losses.BinaryCrossentropy(), \n",
    "              metrics = [keras.metrics.BinaryAccuracy(), \n",
    "                         keras.metrics.Precision(), \n",
    "                         keras.metrics.Recall(),\n",
    "                         keras.metrics.AUC(),\n",
    "                         keras.metrics.FalseNegatives(),\n",
    "                         keras.metrics.FalsePositives(),\n",
    "                         keras.metrics.TrueNegatives(),\n",
    "                         keras.metrics.TruePositives()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x14dcba81e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_model.load_weights(TEMPORAL_PATH + 'checkpoint_final_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(fp, num_segments):\n",
    "    vid_container = av.open(fp)\n",
    "    vid_stream = vid_container.streams.video[0]\n",
    "    frame_count = vid_stream.frames\n",
    "\n",
    "    segment_dividers = get_segment_dividers(frame_count, num_segments)\n",
    "\n",
    "    vid_container.seek(0)\n",
    "    frame_list = [frame.to_image() for frame in vid_container.decode()]\n",
    "\n",
    "    residuals = []\n",
    "    start_index = 0\n",
    "    for sd in segment_dividers:\n",
    "        residuals.append(frame_list[start_index:sd])\n",
    "        start_index = sd\n",
    "    \n",
    "    residuals.append(frame_list[start_index:])\n",
    "\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_temporal_score(model, fp):\n",
    "    residuals = get_residuals(fp, num_segments=3)\n",
    "\n",
    "    results = []\n",
    "    for residual_set in residuals:\n",
    "        tf_frames = []\n",
    "\n",
    "        for frame in residual_set:\n",
    "            tf_frames.append(img_to_array(tf.image.resize(frame, size = [224, 224])))\n",
    "\n",
    "        tf_frames = np.asarray(tf_frames)\n",
    "        result = model.predict(tf_frames, verbose=0)\n",
    "        results.append(np.average(result))\n",
    "\n",
    "    max_val = np.max(results)\n",
    "    min_val = np.min(results)\n",
    "\n",
    "    return max_val if 1 - max_val < min_val else min_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(fp):\n",
    "    extract_iframes(fp)\n",
    "    save_cropped_faces_to_video(INTERMEDIARY_DIR + IFRAME_DIR + os.path.split(fp)[1], -1)\n",
    "    extract_residuals(fp)\n",
    "    t_score = calculate_temporal_score(temporal_model, INTERMEDIARY_DIR + RESIDUAL_DIR + os.path.split(fp)[1])\n",
    "\n",
    "    print(t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33128887\n"
     ]
    }
   ],
   "source": [
    "filename='temp_r1.mp4'\n",
    "# filename=None\n",
    "\n",
    "# If no filename was given, process all videos in input directory\n",
    "if filename == None or not os.path.exists(filename):\n",
    "    for video in os.listdir(INPUT_DIR):\n",
    "        process_video(INPUT_DIR + video)\n",
    "\n",
    "        print(f'Video processed: {video}')\n",
    "\n",
    "# If filename is a valid file in root directory, process only that file\n",
    "else:\n",
    "    process_video(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
