{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq9_NfM01bAv"
      },
      "source": [
        "# Libraries Used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE15KxFc1bA7"
      },
      "source": [
        "* ffmpeg-python\n",
        "* av\n",
        "* cmake\n",
        "* dlib  (based on the python version)\n",
        "* face-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/Celeb-DF\\ v1/\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY1acu8nB5-9",
        "outputId": "3a6630ae-4fd4-48d8-a7b3-af085efa2537"
      },
      "outputs": [],
      "source": [
        "%pip install ffmpeg-python\n",
        "%pip install av\n",
        "%pip install cmake\n",
        "%pip install dlib\n",
        "%pip install face-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUOcxd9SQraT"
      },
      "source": [
        "# **MESONET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D-mUBvSLv6ZN"
      },
      "outputs": [],
      "source": [
        "import av\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import shutil\n",
        "import imghdr\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "DS_ORG = './dataset_original/'\n",
        "DS_IFRAME = './dataset_IFrames/'\n",
        "DS_FACE = './dataset_face/'\n",
        "DS_FINAL = './dataset_final/'\n",
        "DS_SEG = './dataset_segments/'\n",
        "DS_RAW = './dataset_raw/'\n",
        "DS_RES = './dataset_residuals/'\n",
        "\n",
        "MS_TRAIN = './dataset_mesonet/train_dataset/'\n",
        "MS_TEST = './dataset_mesonet/test_dataset/'\n",
        "\n",
        "CELEB_REAL = 'Celeb-real/'\n",
        "CELEB_FAKE = 'Celeb-synthesis/'\n",
        "YT_REAL = 'YouTube-real/'\n",
        "\n",
        "REAL_VIDS = 'real_videos/'\n",
        "FAKE_VIDS = 'fake_videos/'\n",
        "\n",
        "SEG = ['seg_1_', 'seg_2_', 'seg_3_']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-XCfHamQQ0wc"
      },
      "outputs": [],
      "source": [
        "def create_model(input_size):\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(input_shape=input_size, filters=8, kernel_size=3, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
        "\n",
        "  model.add(layers.Conv2D(input_shape=(128, 128, 8), filters=8, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Conv2D(input_shape=(64, 64, 8), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Conv2D(input_shape=(16, 16, 16), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(layers.Dense(16, activation='LeakyReLU'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  return model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgfZce5lxvku",
        "outputId": "b0678b72-cbde-4405-f0af-e407e36fdc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 8)       224       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 8)      32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 8)       1608      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 16)        3216      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 16)        6416      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,656\n",
            "Trainable params: 11,560\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_size = (256, 256, 3)\n",
        "model = create_model(input_size)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IokdF4mk2w5a"
      },
      "source": [
        "## DATASET CREATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKywoZ264zPJ"
      },
      "outputs": [],
      "source": [
        "# dir_real = 'dataset_REAL/'\n",
        "# dir_fake = 'dataset_FAKE/'\n",
        "# dir_train = './training_data/'\n",
        "# dir_test = './testing_data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if os.path.exists(dir_train + dir_real) or os.path.exists(dir_train + dir_fake):\n",
        "#   shutil.rmtree(dir_real)\n",
        "#   shutil.rmtree(dir_fake)\n",
        "# os.makedirs(dir_train + dir_real)\n",
        "# os.makedirs(dir_train + dir_fake)\n",
        "# os.makedirs(dir_test + dir_real)\n",
        "# os.makedirs(dir_test + dir_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QBi0phmw3ZbK"
      },
      "outputs": [],
      "source": [
        "def dataset_extract_frames(source_path, dest_path, vid, tag, count):\n",
        "  frame_count = 0\n",
        "\n",
        "  if(imghdr.what(os.path.join(source_path, vid)) == 'jpeg'):\n",
        "    image = Image.open(source_path + vid)\n",
        "    image.save(f'{dest_path}/vid_{tag}{count}_fr_{frame_count}.jpg')\n",
        "    \n",
        "    return\n",
        "\n",
        "  vid = av.open(source_path + vid)\n",
        "  for frame in vid.decode():\n",
        "    image = frame.to_image()\n",
        "    image.save(f'{dest_path}/vid_{tag}{count}_fr_{frame_count}.jpg')\n",
        "\n",
        "    frame_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "93EnsQWhfSsm"
      },
      "outputs": [],
      "source": [
        "#extracting frames from Celeb-real face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + CELEB_REAL\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + REAL_VIDS, video, 'cr', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZALiQjgu84s2"
      },
      "outputs": [],
      "source": [
        "#extracting frames from YouTube-real face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + YT_REAL\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + REAL_VIDS, video, 'yr', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WRw_64n1PnI4"
      },
      "outputs": [],
      "source": [
        "#extracting frames from Celeb-synthesis face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + CELEB_FAKE\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + FAKE_VIDS, video, 'cf', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2Uks_VAlvLb2"
      },
      "outputs": [],
      "source": [
        "#extracting test data\n",
        "\n",
        "def extract_test_data(source_path):\n",
        "  frame_list = []\n",
        "  for frame in os.listdir(source_path):\n",
        "    frame_path = os.path.join(source_path, frame)\n",
        "    frame_list.append(frame_path)\n",
        "\n",
        "  size = int(20/100 * len(frame_list))\n",
        "  sampled_list = random.sample(frame_list, size)\n",
        "  return sampled_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qYikegxkYQ5x"
      },
      "outputs": [],
      "source": [
        "#extracting test data from real dataset\n",
        "\n",
        "source_path = MS_TRAIN + REAL_VIDS\n",
        "sampled_list = extract_test_data(source_path)\n",
        "for frame_path in sampled_list:\n",
        "  shutil.copy(frame_path, os.path.join(MS_TEST + REAL_VIDS, os.path.basename(frame_path)))\n",
        "  os.remove(frame_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xs2o57qR0blt"
      },
      "outputs": [],
      "source": [
        "#extracting test data from fake dataset\n",
        "\n",
        "source_path = MS_TRAIN + FAKE_VIDS\n",
        "sampled_list = extract_test_data(source_path)\n",
        "for frame_path in sampled_list:\n",
        "  shutil.copy(frame_path, os.path.join(MS_TEST + FAKE_VIDS, os.path.basename(frame_path)))\n",
        "  os.remove(frame_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keras Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NseO3UFkCBWz"
      },
      "outputs": [],
      "source": [
        "#creating dataset from folders\n",
        "def create_dataset(dir_path):\n",
        "  ds = keras.utils.image_dataset_from_directory(\n",
        "      directory = dir_path,\n",
        "      labels = 'inferred',\n",
        "      label_mode = 'binary',\n",
        "      batch_size = 32,\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = True,\n",
        "      validation_split = 0.2,\n",
        "      subset = 'validation',\n",
        "      seed = 1\n",
        "  )\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "2xQOGd1_FBfE",
        "outputId": "28d5f1d8-238a-4829-9ac7-2f35a331cea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22627 files belonging to 2 classes.\n",
            "Using 4525 files for validation.\n",
            "(32, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "      directory = MS_TRAIN,\n",
        "      labels = 'inferred',\n",
        "      label_mode = 'binary',\n",
        "      batch_size = 32,\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = True,\n",
        "      validation_split = 0.2,\n",
        "      subset = 'validation',\n",
        "      seed = 1\n",
        "  )\n",
        "for data, labels in train_ds.take(1):\n",
        "  print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory=MS_TEST,\n",
        "    labels='inferred',\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "for data, labels in test_ds.take(1):\n",
        "  print(data.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "634b966a65970263d64a39f28ca9ed21ee1352c353852874a3701cf42e66fa53"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
