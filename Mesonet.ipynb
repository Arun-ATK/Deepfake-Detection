{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq9_NfM01bAv"
      },
      "source": [
        "# Libraries Used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE15KxFc1bA7"
      },
      "source": [
        "* ffmpeg-python\n",
        "* av\n",
        "* cmake\n",
        "* dlib  (based on the python version)\n",
        "* face-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCNM7aYyTUOe",
        "outputId": "125b71b8-f058-4580-a7f0-332883bd61c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QoaPfQnyRwnf",
        "outputId": "78fcced7-2aca-4d71-b5ac-a42e9a653125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FYP/Celeb DF v1 Dataset\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/FYP/Celeb DF v1 Dataset'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd drive/MyDrive/FYP/Celeb DF\\ v1\\ Dataset/\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY1acu8nB5-9",
        "outputId": "f74eaedf-5d08-4c44-a2fb-78b7b211d359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting av\n",
            "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-10.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (3.22.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.8/dist-packages (19.24.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face-recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from face-recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.8/dist-packages (from face-recognition) (19.24.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from face-recognition) (1.22.4)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from face-recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=0d182ca0fc60047f04bcf4d461c9b655b9a22d0e85404ff019d0416b0a34d947\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/4b/8f/751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ],
      "source": [
        "%pip install ffmpeg-python\n",
        "%pip install av\n",
        "%pip install cmake\n",
        "%pip install dlib\n",
        "%pip install face-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUOcxd9SQraT"
      },
      "source": [
        "# **MESONET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D-mUBvSLv6ZN"
      },
      "outputs": [],
      "source": [
        "import av\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import shutil\n",
        "import imghdr\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iA_RZXqHTUOj"
      },
      "outputs": [],
      "source": [
        "DS_ORG = './dataset_original/'\n",
        "DS_IFRAME = './dataset_IFrames/'\n",
        "DS_FACE = './dataset_face/'\n",
        "DS_FINAL = './dataset_final/'\n",
        "DS_SEG = './dataset_segments/'\n",
        "DS_RAW = './dataset_raw/'\n",
        "DS_RES = './dataset_residuals/'\n",
        "\n",
        "MS_TRAIN = './dataset_mesonet/train_dataset/'\n",
        "MS_TEST = './dataset_mesonet/test_dataset/'\n",
        "MS_MODEL = './dataset_mesonet/models'\n",
        "\n",
        "CELEB_REAL = 'Celeb-real/'\n",
        "CELEB_FAKE = 'Celeb-synthesis/'\n",
        "YT_REAL = 'YouTube-real/'\n",
        "\n",
        "REAL_VIDS = 'real_videos/'\n",
        "FAKE_VIDS = 'fake_videos/'\n",
        "\n",
        "SEG = ['seg_1_', 'seg_2_', 'seg_3_']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-XCfHamQQ0wc"
      },
      "outputs": [],
      "source": [
        "def create_model(input_size):\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(input_shape=input_size, filters=8, kernel_size=3, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
        "\n",
        "  model.add(layers.Conv2D(input_shape=(128, 128, 8), filters=8, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(2, 2, padding=\"same\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Conv2D(input_shape=(64, 64, 8), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Conv2D(input_shape=(16, 16, 16), filters=16, kernel_size=5, activation='relu', padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(4, 4, padding=\"same\"))\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(layers.Dense(16))\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  return model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgfZce5lxvku",
        "outputId": "e9c85b41-8384-40b0-d568-6e1f1eec468c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 8)       224       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 8)      32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 8)       1608      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 16)        3216      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 16)        6416      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                4112      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,785\n",
            "Trainable params: 15,689\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_size = (256, 256, 3)\n",
        "model = create_model(input_size)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics = [keras.metrics.BinaryAccuracy(), \n",
        "                         keras.metrics.Precision(), \n",
        "                         keras.metrics.Recall(),\n",
        "                         keras.metrics.AUC()])\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IokdF4mk2w5a"
      },
      "source": [
        "## Frame Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBi0phmw3ZbK"
      },
      "outputs": [],
      "source": [
        "def dataset_extract_frames(source_path, dest_path, vid, tag, count):\n",
        "  frame_count = 0\n",
        "\n",
        "  if(imghdr.what(os.path.join(source_path, vid)) == 'jpeg'):\n",
        "    image = Image.open(source_path + vid)\n",
        "    image.save(f'{dest_path}/vid_{tag}{count}_fr_{frame_count}.jpg')\n",
        "    \n",
        "    return\n",
        "\n",
        "  vid = av.open(source_path + vid)\n",
        "  for frame in vid.decode():\n",
        "    image = frame.to_image()\n",
        "    image.save(f'{dest_path}/vid_{tag}{count}_fr_{frame_count}.jpg')\n",
        "\n",
        "    frame_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93EnsQWhfSsm"
      },
      "outputs": [],
      "source": [
        "#extracting frames from Celeb-real face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + CELEB_REAL\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + REAL_VIDS, video, 'cr', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZALiQjgu84s2"
      },
      "outputs": [],
      "source": [
        "#extracting frames from YouTube-real face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + YT_REAL\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + REAL_VIDS, video, 'yr', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRw_64n1PnI4"
      },
      "outputs": [],
      "source": [
        "#extracting frames from Celeb-synthesis face-cropped data\n",
        "vid_count = 1\n",
        "source_path = DS_FACE + CELEB_FAKE\n",
        "for video in os.listdir(source_path):\n",
        "  # print(video, vid_count)\n",
        "  dataset_extract_frames(source_path, MS_TRAIN + FAKE_VIDS, video, 'cf', vid_count)\n",
        "  vid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uks_VAlvLb2"
      },
      "outputs": [],
      "source": [
        "#extracting test data\n",
        "\n",
        "def extract_test_data(source_path):\n",
        "  frame_list = []\n",
        "  for frame in os.listdir(source_path):\n",
        "    frame_path = os.path.join(source_path, frame)\n",
        "    frame_list.append(frame_path)\n",
        "\n",
        "  size = int(20/100 * len(frame_list))\n",
        "  sampled_list = random.sample(frame_list, size)\n",
        "  return sampled_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYikegxkYQ5x"
      },
      "outputs": [],
      "source": [
        "#extracting test data from real dataset\n",
        "\n",
        "source_path = MS_TRAIN + REAL_VIDS\n",
        "sampled_list = extract_test_data(source_path)\n",
        "for frame_path in sampled_list:\n",
        "  shutil.copy(frame_path, os.path.join(MS_TEST + REAL_VIDS, os.path.basename(frame_path)))\n",
        "  os.remove(frame_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs2o57qR0blt"
      },
      "outputs": [],
      "source": [
        "#extracting test data from fake dataset\n",
        "\n",
        "source_path = MS_TRAIN + FAKE_VIDS\n",
        "sampled_list = extract_test_data(source_path)\n",
        "for frame_path in sampled_list:\n",
        "  shutil.copy(frame_path, os.path.join(MS_TEST + FAKE_VIDS, os.path.basename(frame_path)))\n",
        "  os.remove(frame_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NseO3UFkCBWz"
      },
      "outputs": [],
      "source": [
        "#creating dataset from folders\n",
        "def create_dataset(dir_path):\n",
        "  ds = keras.utils.image_dataset_from_directory(\n",
        "      directory = dir_path,\n",
        "      labels = 'inferred',\n",
        "      label_mode = 'binary',\n",
        "      batch_size = 32,\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = True,\n",
        "      validation_split = 0.2,\n",
        "      subset = 'validation',\n",
        "      seed = 1\n",
        "  )\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xQOGd1_FBfE",
        "outputId": "df378c14-0563-4dd2-fa3d-0ce5156ca1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22627 files belonging to 2 classes.\n",
            "Using 18102 files for training.\n",
            "Using 4525 files for validation.\n",
            "(32, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "(train_ds, val_ds) = keras.utils.image_dataset_from_directory(\n",
        "      directory = MS_TRAIN,\n",
        "      labels = 'inferred',\n",
        "      label_mode = 'binary',\n",
        "      batch_size = 32,\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = True,\n",
        "      validation_split = 0.2,\n",
        "      subset = 'both',\n",
        "      seed = 1\n",
        "  )\n",
        "for data, labels in train_ds.take(1):\n",
        "  print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U971iBD4TUOq",
        "outputId": "320aadb7-811a-4d0e-a710-d39728e194b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5655 files belonging to 2 classes.\n",
            "(32, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory=MS_TEST,\n",
        "    labels='inferred',\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "for data, labels in test_ds.take(1):\n",
        "  print(data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load from checkpoint (if exists)\n",
        "try:\n",
        "    saved_model = keras.models.load_model(MS_MODEL)\n",
        "    model = saved_model\n",
        "\n",
        "except IOError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKKOsMgFWYfM",
        "outputId": "f49004f6-d032-4014-e84c-3ed0d57b5f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 47s - loss: 0.6395 - binary_accuracy: 0.6655 - precision: 0.6805 - recall: 0.6807 - val_loss: 0.5309 - val_binary_accuracy: 0.7399 - val_precision: 0.7502 - val_recall: 0.7389 - 47s/epoch - 83ms/step\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 48s - loss: 0.6152 - binary_accuracy: 0.6768 - precision: 0.6918 - recall: 0.6903 - val_loss: 0.5222 - val_binary_accuracy: 0.7503 - val_precision: 0.7593 - val_recall: 0.7514 - 48s/epoch - 84ms/step\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 50s - loss: 0.5874 - binary_accuracy: 0.6945 - precision: 0.7065 - recall: 0.7126 - val_loss: 0.5095 - val_binary_accuracy: 0.7531 - val_precision: 0.7324 - val_recall: 0.8173 - 50s/epoch - 87ms/step\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 47s - loss: 0.5720 - binary_accuracy: 0.7061 - precision: 0.7208 - recall: 0.7161 - val_loss: 0.5015 - val_binary_accuracy: 0.7717 - val_precision: 0.7788 - val_recall: 0.7751 - 47s/epoch - 82ms/step\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 47s - loss: 0.5564 - binary_accuracy: 0.7177 - precision: 0.7335 - recall: 0.7240 - val_loss: 0.4791 - val_binary_accuracy: 0.7839 - val_precision: 0.8246 - val_recall: 0.7350 - 47s/epoch - 84ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f031ad850>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_epochs = 20\n",
        "\n",
        "model.fit(train_ds, \n",
        "          epochs=max_epochs, \n",
        "          validation_data=val_ds,\n",
        "          callbacks=keras.callbacks.ModelCheckpoint(MS_MODEL),\n",
        "          verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test dataset metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc, prec, rec, auc = model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss:\\t{loss:.4f}')\n",
        "print(f'Accuracy:\\t{acc:.4f}')\n",
        "print(f'Precision:\\t{prec:.4f}')\n",
        "print(f'Recall:\\t{rec:.4f}')\n",
        "print(f'AUC:\\t{rec:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXAgr_Edl_hY"
      },
      "source": [
        "## Testing Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l8Mxg3VX8Jz",
        "outputId": "e2f4f562-83a4-40f9-aa2d-a5ef5d95dcc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f9f032ded00>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model = keras.models.load_model(MS_MODEL)\n",
        "new_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu_gsZ3mlvND",
        "outputId": "1e2632d1-97f1-4f4a-ea9b-28aec8a4c1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 52s - loss: 0.5269 - binary_accuracy: 0.7397 - precision: 0.7585 - recall: 0.7378 - val_loss: 0.4590 - val_binary_accuracy: 0.8020 - val_precision: 0.8401 - val_recall: 0.7583 - 52s/epoch - 92ms/step\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 48s - loss: 0.5091 - binary_accuracy: 0.7522 - precision: 0.7731 - recall: 0.7458 - val_loss: 0.4488 - val_binary_accuracy: 0.8082 - val_precision: 0.8208 - val_recall: 0.8009 - 48s/epoch - 85ms/step\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 46s - loss: 0.4856 - binary_accuracy: 0.7678 - precision: 0.7877 - recall: 0.7618 - val_loss: 0.4322 - val_binary_accuracy: 0.8188 - val_precision: 0.8515 - val_recall: 0.7833 - 46s/epoch - 82ms/step\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 47s - loss: 0.4790 - binary_accuracy: 0.7704 - precision: 0.7915 - recall: 0.7623 - val_loss: 0.4223 - val_binary_accuracy: 0.8197 - val_precision: 0.8352 - val_recall: 0.8078 - 47s/epoch - 83ms/step\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "566/566 - 45s - loss: 0.4649 - binary_accuracy: 0.7814 - precision: 0.8076 - recall: 0.7646 - val_loss: 0.4134 - val_binary_accuracy: 0.8219 - val_precision: 0.8568 - val_recall: 0.7837 - 45s/epoch - 80ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f033974f0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model.fit(train_ds, \n",
        "          epochs=5, \n",
        "          validation_data=val_ds,\n",
        "          callbacks=keras.callbacks.ModelCheckpoint(MS_MODEL),\n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIYZysVCmK6L",
        "outputId": "e890d7b4-a44d-456c-8a46-248464fe73e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "177/177 [==============================] - 12s 65ms/step - loss: 0.4123 - binary_accuracy: 0.8212 - precision: 0.8613 - recall: 0.7833\n",
            "Loss: 0.4123\n",
            "Accuracy: 0.8212\n",
            "Precision: 0.8613\n",
            "Recall: 0.7833\n"
          ]
        }
      ],
      "source": [
        "loss, acc, prec, rec = new_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss:.4f}')\n",
        "print(f'Accuracy: {acc:.4f}')\n",
        "print(f'Precision: {prec:.4f}')\n",
        "print(f'Recall: {rec:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "634b966a65970263d64a39f28ca9ed21ee1352c353852874a3701cf42e66fa53"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
